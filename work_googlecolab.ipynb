{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "work.ipynb のコピー のコピー",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NdRBsFqJHcK",
        "colab_type": "text"
      },
      "source": [
        "# 本ドキュメントについて\n",
        "\n",
        "このドキュメントは、検証履歴の保存と整理を目的としています。\n",
        "\n",
        "## 本研究のテーマ\n",
        "\n",
        "レコメンデーションへディープラーニングを応用する方法を検証します。\n",
        "\n",
        "## 先行研究\n",
        "\n",
        "2016年以降、いくつかの研究がディープラーニングを使ったレコメンデーションアルゴリズムについて言及しています。\n",
        "\n",
        "特に研究が盛んなのは、クリック率予測問題の領域で、FNNやWide&Deepなどの手法が提案されています。\n",
        "\n",
        "これらの先行手法では、Criteoが提供するWeb広告のクリック履歴データを用いて検証しており、(ユーザー, アイテム, 満足度スコア)の組み合わせ構造をもつ、アイテムレコメンデーションのデータでの検証はそれほどありません。\n",
        "\n",
        "## 本研究の意義\n",
        "\n",
        "これらの先行研究を参考にしつつ、アイテムレコメンデーションでのディープラーニングの応用を検証を行います。\n",
        "\n",
        "この場合、なぜディープラーニングなのかについて整理を行います。\n",
        "\n",
        "1. 既存の(ユーザー, アイテム)を、例えば(ユーザー, アイテム, 時間)のより高次元な組み合わせを扱えるようになります。\n",
        "2. 転移学習により、学習済みの中間重みを別のレコメンデーションシステムに適応可能になり、総体としての改善が見込まれます。（中川さんのアイデア）\n",
        "3. \n",
        "\n",
        "(1) については、特に「時間」を加味することは非常に有効であることが他の研究でもすでに指摘されており、多次元の組み合わせでレコメンデーションを行う有効性はすでに知られています。\n",
        "また、2010年に提案された Factorization Machine(FM) は、理論的には多次元の組み合わせのレコメンデーションを計算できます。\n",
        "\n",
        "一方で、高次元な組み合わせが疎データ問題をより悪化させ、性能に影響を与えることが懸念されています。\n",
        "この問題の解決をディープラーニングで実現できるかが、本研究の要点の一つとなります。\n",
        "\n",
        "(2)については、本来は研究を分けて行うべきだと思いますが、簡単に言及しておきます。\n",
        "ディープラーニングでは、学習済みのweightを別の学習セットに転用する転移学習が盛んで、これが多くの分野で性能を発揮しています。\n",
        "レコメンデーションはそのアプリケーションの特異性が強く、学習やモデルを調整する必要がありますが、転移学習を用いればそれを緩和できます。\n",
        "画像判別や文章解析で実績の多い転移学習が、レコメンデーションでも有効なのかを検証するのも必要な研究でしょう。\n",
        "\n",
        "\n",
        "## 以降から、\n",
        "\n",
        "プログラムコードで、検証の過程を保存、整理していきます。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8LMxC88JbBs",
        "colab_type": "code",
        "outputId": "a4b9558c-8e76-429c-81e9-5db5dc3906f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "source": [
        "# download this repository\n",
        "!git clone --recurse-submodules https://github.com/uchida-takumi/thesis_20190715\n",
        "# when cd directory, should use %.\n",
        "%cd thesis_20190715\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'thesis_20190715'...\n",
            "remote: Enumerating objects: 148, done.\u001b[K\n",
            "remote: Counting objects: 100% (148/148), done.\u001b[K\n",
            "remote: Compressing objects: 100% (107/107), done.\u001b[K\n",
            "remote: Total 148 (delta 77), reused 111 (delta 40), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (148/148), 1.05 MiB | 1.42 MiB/s, done.\n",
            "Resolving deltas: 100% (77/77), done.\n",
            "Submodule 'src/pyFM' (https://github.com/uchida-takumi/pyFM) registered for path 'src/pyFM'\n",
            "Cloning into '/content/thesis_20190715/src/pyFM'...\n",
            "remote: Enumerating objects: 5, done.        \n",
            "remote: Counting objects: 100% (5/5), done.        \n",
            "remote: Compressing objects: 100% (5/5), done.        \n",
            "remote: Total 269 (delta 0), reused 3 (delta 0), pack-reused 264\n",
            "Receiving objects: 100% (269/269), 1.38 MiB | 1.27 MiB/s, done.\n",
            "Resolving deltas: 100% (69/69), done.\n",
            "Submodule path 'src/pyFM': checked out '2e47265fffe3f029433333953a14977e357d2701'\n",
            "/content/thesis_20190715\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svdC381mP_J7",
        "colab_type": "code",
        "outputId": "c4c6b14f-41de-4fde-f362-edccc4a735d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# setup module\n",
        "!pip install -r requirements.txt\n",
        "!pip install surprise\n",
        "!pip install src/pyFM/\n",
        "!pip install tensorflow-gpu==2.0.0-beta1\n",
        "\n",
        "# download data\n",
        "!mkdir data\n",
        "%cd data\n",
        "!curl -OL http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
        "!unzip ml-latest-small.zip\n",
        "%cd .."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 13)) (1.16.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 14)) (0.24.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 15)) (0.21.3)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 16)) (0.29.13)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 14)) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 14)) (2018.9)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r requirements.txt (line 15)) (1.3.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r requirements.txt (line 15)) (0.13.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas->-r requirements.txt (line 14)) (1.12.0)\n",
            "Collecting surprise\n",
            "  Downloading https://files.pythonhosted.org/packages/61/de/e5cba8682201fcf9c3719a6fdda95693468ed061945493dea2dd37c5618b/surprise-0.1-py2.py3-none-any.whl\n",
            "Collecting scikit-surprise (from surprise)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4d/fc/cd4210b247d1dca421c25994740cbbf03c5e980e31881f10eaddf45fdab0/scikit-surprise-1.0.6.tar.gz (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.16.4)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.3.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.12.0)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.0.6-cp36-cp36m-linux_x86_64.whl size=1683522 sha256=0a2cbd8ea68bd19b0faf78e316b989e674390cb1338cb5a57974052208e5b219\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/c0/55/3a28eab06b53c220015063ebbdb81213cd3dcbb72c088251ec\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.0.6 surprise-0.1\n",
            "Processing ./src/pyFM\n",
            "Building wheels for collected packages: pyfm\n",
            "  Building wheel for pyfm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyfm: filename=pyfm-0.0.0-cp36-cp36m-linux_x86_64.whl size=221355 sha256=e691c6a1b00b4000e61fbac9d54107236a1b554a2145b3c3088722b475567173\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jqd4qls4/wheels/1d/a4/09/df5064c3cb030c957d4d2eb611a67d6ac039930648de85b56c\n",
            "Successfully built pyfm\n",
            "Installing collected packages: pyfm\n",
            "Successfully installed pyfm-0.0.0\n",
            "Collecting tensorflow-gpu==2.0.0-beta1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/53/e18c5e7a2263d3581a979645a185804782e59b8e13f42b9c3c3cfb5bb503/tensorflow_gpu-2.0.0b1-cp36-cp36m-manylinux1_x86_64.whl (348.9MB)\n",
            "\u001b[K     |████████████████████████████████| 348.9MB 72kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.1.7)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (3.7.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.16.4)\n",
            "Collecting tb-nightly<1.14.0a20190604,>=1.14.0a20190603 (from tensorflow-gpu==2.0.0-beta1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/96/571b875cd81dda9d5dfa1422a4f9d749e67c0a8d4f4f0b33a4e5f5f35e27/tb_nightly-1.14.0a20190603-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 26.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.11.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.2.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.0.8)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.33.4)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.8.0)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 (from tensorflow-gpu==2.0.0-beta1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/dd/99c47dd007dcf10d63fd895611b063732646f23059c618a373e85019eb0e/tf_estimator_nightly-1.14.0.dev2019060501-py2.py3-none-any.whl (496kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 45.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-beta1) (41.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta1) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta1) (0.15.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-beta1) (2.8.0)\n",
            "Installing collected packages: tb-nightly, tf-estimator-nightly, tensorflow-gpu\n",
            "Successfully installed tb-nightly-1.14.0a20190603 tensorflow-gpu-2.0.0b1 tf-estimator-nightly-1.14.0.dev2019060501\n",
            "/content/thesis_20190715/data\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  955k  100  955k    0     0   513k      0  0:00:01  0:00:01 --:--:--  513k\n",
            "Archive:  ml-latest-small.zip\n",
            "   creating: ml-latest-small/\n",
            "  inflating: ml-latest-small/links.csv  \n",
            "  inflating: ml-latest-small/tags.csv  \n",
            "  inflating: ml-latest-small/ratings.csv  \n",
            "  inflating: ml-latest-small/README.txt  \n",
            "  inflating: ml-latest-small/movies.csv  \n",
            "/content/thesis_20190715\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL5WxdmlJHcL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 学習中にWarningが発生するのでメッセージをオフにします。\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "#######################\n",
        "# 1. load data from src/modules/inputs.py\n",
        "'''\n",
        "ここで読み込んだデータは、MovieLensのショートデータです。\n",
        "'''\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "csv_fp = 'data/ml-latest-small/ratings.csv'\n",
        "data = pd.read_csv(csv_fp)\n",
        "column_names = ['userId', 'movieId', 'timestamp']\n",
        "label_name = 'rating'\n",
        "\n",
        "X, y = data[column_names].values, data[label_name].values\n",
        "\n",
        "#　テストコーディング用\n",
        "#X, y = X[:1000], y[:1000]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYbosll0JHcO",
        "colab_type": "code",
        "outputId": "de53ebd7-35e9-48d0-a836-acd58397b87b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "# X は [user, item, timestamp] です。\n",
        "X"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[         1,          1,  964982703],\n",
              "       [         1,          3,  964981247],\n",
              "       [         1,          6,  964982224],\n",
              "       ...,\n",
              "       [       610,     168250, 1494273047],\n",
              "       [       610,     168252, 1493846352],\n",
              "       [       610,     170875, 1493846415]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXhn7NouJHcT",
        "colab_type": "code",
        "outputId": "d4246689-79ad-4b0b-b828-6f973247500a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# y は　　rating です。\n",
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4., 4., 4., ..., 5., 5., 3.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWRMiZgeJHcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################\n",
        "# 2. define same interface of recommendater models\n",
        "'''\n",
        "ここでは、検証する手法のgrid-searchによるパラメータチューニングを行います。\n",
        "用いるvalidation セットは、上述で読み込んだ X,y です。\n",
        "train, test セットは別のデータを用いるとし、このデータでgrid-searchを行います。\n",
        "'''\n",
        "# 自作のgrid_search　モジュールを読み込みます。\n",
        "from src.grid_search import grid_search"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2fJLbhAJHcX",
        "colab_type": "code",
        "outputId": "2a60ab84-f7ba-4e9a-fc0f-a21a73116916",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "#  BaseLine である MatrixFactorization　のパラメータチューニング\n",
        "from surprise import SVD  \n",
        "from src.surprise_algo_wrapper import surprise_algo_wrapper # I/F統一用のラッパー\n",
        "\n",
        "model_module = SVD\n",
        "wrapper = surprise_algo_wrapper\n",
        "\n",
        "params = [\n",
        "        {'n_factors':4,   'reg_all':0.010},\n",
        "        {'n_factors':8,   'reg_all':0.010}, # the BEST\n",
        "        #{'n_factors':16,   'reg_all':0.010},\n",
        "        #{'n_factors':8,   'reg_all':0.001}, \n",
        "        #{'n_factors':8,   'reg_all':0.100}, \n",
        "        ]\n",
        "models = [wrapper(model_module(**param)) for param in params]\n",
        "best_indice, scores, each_scores = grid_search(X, y, models)    \n",
        "print('scores={}'.format(scores))\n",
        "print('best_param={}'.format(params[best_indice]))\n",
        "print('each_scores={}'.format(each_scores))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "k_hold = 1/3\n",
            "k_hold = 2/3\n",
            "k_hold = 3/3\n",
            "k_hold = 1/3\n",
            "k_hold = 2/3\n",
            "k_hold = 3/3\n",
            "scores=[0.4923993327850942, 0.49091919831733594]\n",
            "best_param={'n_factors': 4, 'reg_all': 0.01}\n",
            "each_scores=[[0.4892032762472077, 0.4968152866242038, 0.49117943548387094], [0.4854802680565897, 0.5003821656050955, 0.48689516129032256]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT_krYugJHcZ",
        "colab_type": "code",
        "outputId": "939c09ac-2314-485c-be8a-543089c4da69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "source": [
        "#  BaseLine である factorization machine　のパラメータチューニング\n",
        "from pyfm.pylibfm import FM # factorization machine\n",
        "from src.pyfm_model_wrapper import pyfm_model_wrapper # I/F統一用のラッパー\n",
        "\n",
        "model_module = FM\n",
        "wrapper = pyfm_model_wrapper\n",
        "\n",
        "'''\n",
        "    num_factors : int # 大きすぎると、python kernelが原因不明のシャットダウンを起こす？\n",
        "        The dimensionality of the factorized 2-way interactions\n",
        "    num_iter : int\n",
        "        Number of iterations\n",
        "    init_stdev : double, optional\n",
        "        Standard deviation for initialization of 2-way factors.\n",
        "        Defaults to 0.01.\n",
        "    validation_size : double, optional # ここを0にしているとシャットダウンしやすい？\n",
        "        Proportion of the training set to use for validation.\n",
        "        Defaults to 0.01.\n",
        "    task : string\n",
        "        regression: Labels are real values.\n",
        "        classification: Labels are either positive or negative.\n",
        "    seed : int\n",
        "        The seed of the pseudo random number generator\n",
        "    reg_0 : float [注：自分でライブラリを改造して追加] \n",
        "        The regularization parameter of w0\n",
        "    reg_w : float [注：自分でライブラリを改造して追加]\n",
        "        The regularization parameter of w\n",
        "    reg_v : float [注：自分でライブラリを改造して追加]\n",
        "        The regularization parameter of each element in v\n",
        "\n",
        "'''\n",
        "\n",
        "params = [\n",
        "        #{'num_factors':2, 'num_iter':2, 'reg_0':0.0, 'reg_w':0.10, 'reg_v':0.10, 'validation_size':0.01, 'task':'regression'}, \n",
        "        #{'num_factors':4, 'num_iter':2, 'reg_0':0.0, 'reg_w':0.10, 'reg_v':0.10, 'validation_size':0.01, 'task':'regression'}, \n",
        "        {'num_factors':8, 'num_iter':2, 'reg_0':0.0, 'reg_w':0.10, 'reg_v':0.10, 'validation_size':0.01, 'task':'regression'}, \n",
        "        #{'num_factors':16, 'num_iter':2, 'reg_0':0.0, 'reg_w':0.10, 'reg_v':0.10, 'validation_size':0.01, 'task':'regression'}, \n",
        "]\n",
        "models = [wrapper(model_module(**param)) for param in params]\n",
        "best_indice, scores, each_scores = grid_search(X, y, models)\n",
        "print('scores={}'.format(scores))\n",
        "print('best_param={}'.format(params[best_indice]))\n",
        "print('each_scores={}'.format(each_scores))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "k_hold = 1/3\n",
            "Creating validation dataset of 0.01 of training for adaptive regularization\n",
            "-- Epoch 1\n",
            "Training MSE: 0.43850\n",
            "-- Epoch 2\n",
            "Training MSE: 0.38908\n",
            "k_hold = 2/3\n",
            "Creating validation dataset of 0.01 of training for adaptive regularization\n",
            "-- Epoch 1\n",
            "Training MSE: 0.43853\n",
            "-- Epoch 2\n",
            "Training MSE: 0.38808\n",
            "k_hold = 3/3\n",
            "Creating validation dataset of 0.01 of training for adaptive regularization\n",
            "-- Epoch 1\n",
            "Training MSE: 0.43981\n",
            "-- Epoch 2\n",
            "Training MSE: 0.38940\n",
            "scores=[0.0]\n",
            "best_param={'num_factors': 8, 'num_iter': 2, 'reg_0': 0.0, 'reg_w': 0.1, 'reg_v': 0.1, 'validation_size': 0.01, 'task': 'regression'}\n",
            "each_scores=[[0.0, 0.0, 0.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JR3h1od8JHcb",
        "colab_type": "code",
        "outputId": "3ea4d0a1-d256-432f-905b-950a29660600",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#  Re-FNN のパラメータチューニング\n",
        "from src.DNN_recommender import RFNN # Re-FNN\n",
        "from src.keras_model_wrapper import keras_model_wrapper # I/F統一用のラッパー\n",
        "\n",
        "model_module = RFNN\n",
        "wrapper = keras_model_wrapper\n",
        "\n",
        "'''\n",
        "    max_user [int]:\n",
        "        max id number of user.\n",
        "    max_item [int]:\n",
        "        max id number of item.\n",
        "    fix_global_bias [int or None]:\n",
        "        fix global_bias as inputted int. if None, trained global_bias as weight.\n",
        "    embedding_size [int]:\n",
        "        latent factor number.\n",
        "    dnn_hidden_units [array]:\n",
        "        hidden layer size. (ex.) dnn_hidden_units=(62, 128, 62)\n",
        "    l2_reg [float]:\n",
        "        L2 reguralization.\n",
        "'''\n",
        "max_user, max_item = X[:,0].max()+1, X[:,1].max()+1\n",
        "\n",
        "params = [\n",
        "    {'max_user':max_user, 'max_item':max_item, 'embedding_size':8, 'dnn_hidden_units':(64), 'l2_reg':0.01},\n",
        "    {'max_user':max_user, 'max_item':max_item, 'embedding_size':8, 'dnn_hidden_units':(64,64), 'l2_reg':0.01},\n",
        "    {'max_user':max_user, 'max_item':max_item, 'embedding_size':8, 'dnn_hidden_units':(64,64,64), 'l2_reg':0.01},\n",
        "]\n",
        "models = [wrapper(model_module, param, epochs=5, batch_size=124) for param in params]\n",
        "best_indice, scores, each_scores = grid_search(X, y, models)    \n",
        "print('scores={}'.format(scores))\n",
        "print('best_param={}'.format(params[best_indice]))\n",
        "print('each_scores={}'.format(each_scores))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "k_hold = 1/3\n",
            "Train on 700 samples\n",
            "Epoch 1/5\n",
            "700/700 [==============================] - 0s 568us/sample - loss: 14.8787\n",
            "Epoch 2/5\n",
            "700/700 [==============================] - 0s 130us/sample - loss: 14.5864\n",
            "Epoch 3/5\n",
            "700/700 [==============================] - 0s 131us/sample - loss: 14.2631\n",
            "Epoch 4/5\n",
            "700/700 [==============================] - 0s 135us/sample - loss: 13.8995\n",
            "Epoch 5/5\n",
            "700/700 [==============================] - 0s 160us/sample - loss: 13.4811\n",
            "k_hold = 2/3\n",
            "Train on 700 samples\n",
            "Epoch 1/5\n",
            "700/700 [==============================] - 0s 528us/sample - loss: 14.9705\n",
            "Epoch 2/5\n",
            "700/700 [==============================] - 0s 119us/sample - loss: 14.5290\n",
            "Epoch 3/5\n",
            "700/700 [==============================] - 0s 116us/sample - loss: 14.0356\n",
            "Epoch 4/5\n",
            "700/700 [==============================] - 0s 118us/sample - loss: 13.4712\n",
            "Epoch 5/5\n",
            "700/700 [==============================] - 0s 107us/sample - loss: 12.8320\n",
            "k_hold = 3/3\n",
            "Train on 700 samples\n",
            "Epoch 1/5\n",
            "700/700 [==============================] - 0s 500us/sample - loss: 14.5528\n",
            "Epoch 2/5\n",
            "700/700 [==============================] - 0s 114us/sample - loss: 14.1984\n",
            "Epoch 3/5\n",
            "700/700 [==============================] - 0s 115us/sample - loss: 13.8053\n",
            "Epoch 4/5\n",
            "700/700 [==============================] - 0s 102us/sample - loss: 13.3576\n",
            "Epoch 5/5\n",
            "700/700 [==============================] - 0s 103us/sample - loss: 12.8467\n",
            "k_hold = 1/3\n",
            "Train on 700 samples\n",
            "Epoch 1/5\n",
            "700/700 [==============================] - 0s 568us/sample - loss: 15.4359\n",
            "Epoch 2/5\n",
            "700/700 [==============================] - 0s 123us/sample - loss: 14.9396\n",
            "Epoch 3/5\n",
            "700/700 [==============================] - 0s 112us/sample - loss: 14.3261\n",
            "Epoch 4/5\n",
            "700/700 [==============================] - 0s 128us/sample - loss: 13.5561\n",
            "Epoch 5/5\n",
            "700/700 [==============================] - 0s 128us/sample - loss: 12.5741\n",
            "k_hold = 2/3\n",
            "Train on 700 samples\n",
            "Epoch 1/5\n",
            "700/700 [==============================] - 0s 630us/sample - loss: 15.5465\n",
            "Epoch 2/5\n",
            "700/700 [==============================] - 0s 120us/sample - loss: 14.9518\n",
            "Epoch 3/5\n",
            "700/700 [==============================] - 0s 124us/sample - loss: 14.1914\n",
            "Epoch 4/5\n",
            "700/700 [==============================] - 0s 125us/sample - loss: 13.1771\n",
            "Epoch 5/5\n",
            "700/700 [==============================] - 0s 125us/sample - loss: 11.8527\n",
            "k_hold = 3/3\n",
            "Train on 700 samples\n",
            "Epoch 1/5\n",
            "700/700 [==============================] - 0s 582us/sample - loss: 15.1615\n",
            "Epoch 2/5\n",
            "700/700 [==============================] - 0s 132us/sample - loss: 14.6476\n",
            "Epoch 3/5\n",
            "700/700 [==============================] - 0s 130us/sample - loss: 14.0128\n",
            "Epoch 4/5\n",
            "700/700 [==============================] - 0s 128us/sample - loss: 13.2049\n",
            "Epoch 5/5\n",
            "700/700 [==============================] - 0s 131us/sample - loss: 12.1758\n",
            "k_hold = 1/3\n",
            "Train on 700 samples\n",
            "Epoch 1/5\n",
            "700/700 [==============================] - 0s 687us/sample - loss: 16.0871\n",
            "Epoch 2/5\n",
            "700/700 [==============================] - 0s 123us/sample - loss: 15.4680\n",
            "Epoch 3/5\n",
            "700/700 [==============================] - 0s 128us/sample - loss: 14.6287\n",
            "Epoch 4/5\n",
            "700/700 [==============================] - 0s 121us/sample - loss: 13.4478\n",
            "Epoch 5/5\n",
            "700/700 [==============================] - 0s 128us/sample - loss: 11.7584\n",
            "k_hold = 2/3\n",
            "Train on 700 samples\n",
            "Epoch 1/5\n",
            "700/700 [==============================] - 0s 603us/sample - loss: 16.1990\n",
            "Epoch 2/5\n",
            "700/700 [==============================] - 0s 109us/sample - loss: 15.6267\n",
            "Epoch 3/5\n",
            "700/700 [==============================] - 0s 97us/sample - loss: 14.8670\n",
            "Epoch 4/5\n",
            "700/700 [==============================] - 0s 96us/sample - loss: 13.7962\n",
            "Epoch 5/5\n",
            "700/700 [==============================] - 0s 100us/sample - loss: 12.3018\n",
            "k_hold = 3/3\n",
            "Train on 700 samples\n",
            "Epoch 1/5\n",
            "700/700 [==============================] - 0s 586us/sample - loss: 15.7294\n",
            "Epoch 2/5\n",
            "700/700 [==============================] - 0s 102us/sample - loss: 14.9979\n",
            "Epoch 3/5\n",
            "700/700 [==============================] - 0s 109us/sample - loss: 14.0065\n",
            "Epoch 4/5\n",
            "700/700 [==============================] - 0s 105us/sample - loss: 12.5902\n",
            "Epoch 5/5\n",
            "700/700 [==============================] - 0s 118us/sample - loss: 10.6038\n",
            "scores=[0.0, 0.0, 0.0]\n",
            "best_param={'max_user': 8, 'max_item': 131725, 'embedding_size': 8, 'dnn_hidden_units': 64, 'l2_reg': 0.01}\n",
            "each_scores=[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sf7OHpcdJHck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  Re-Wide&Deep のパラメータチューニング\n",
        "from src.DNN_recommender import R_Wide_and_Deep # Re-FNN\n",
        "from src.keras_model_wrapper import keras_model_wrapper # I/F統一用のラッパー\n",
        "\n",
        "model_module = R_Wide_and_Deep\n",
        "wrapper = keras_model_wrapper\n",
        "\n",
        "'''\n",
        "    max_user [int]:\n",
        "        max id number of user.\n",
        "    max_item [int]:\n",
        "        max id number of item.\n",
        "    fix_global_bias [int or None]:\n",
        "        fix global_bias as inputted int. if None, trained global_bias as weight.\n",
        "    embedding_size [int]:\n",
        "        latent factor number.\n",
        "    dnn_hidden_units [array]:\n",
        "        hidden layer size. (ex.) dnn_hidden_units=(62, 128, 62)\n",
        "    l2_reg [float]:\n",
        "        L2 reguralization.\n",
        "'''\n",
        "max_user, max_item = X[:,0].max()+1, X[:,1].max()+1\n",
        "\n",
        "params = [\n",
        "    #{'max_user':max_user, 'max_item':max_item, 'embedding_size':8, 'dnn_hidden_units':(64), 'l2_reg':0.001},\n",
        "    {'max_user':max_user, 'max_item':max_item, 'embedding_size':8, 'dnn_hidden_units':(64), 'l2_reg':0.010},\n",
        "    #{'max_user':max_user, 'max_item':max_item, 'embedding_size':8, 'dnn_hidden_units':(64), 'l2_reg':0.100},\n",
        "    #{'max_user':max_user, 'max_item':max_item, 'embedding_size':8, 'dnn_hidden_units':(64,64), 'l2_reg':0.01},\n",
        "    #{'max_user':max_user, 'max_item':max_item, 'embedding_size':8, 'dnn_hidden_units':(64,64,64), 'l2_reg':0.01},\n",
        "]\n",
        "models = [wrapper(model_module, param, epochs=5, batch_size=124) for param in params]\n",
        "best_indice, scores, each_scores = grid_search(X, y, models, k_hold=1)    \n",
        "print('scores={}'.format(scores))\n",
        "print('best_param={}'.format(params[best_indice]))\n",
        "print('each_scores={}'.format(each_scores))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3ZBS5YmJHcn",
        "colab_type": "code",
        "outputId": "33ff19de-01ef-4aa1-f893-818a0dab10f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        }
      },
      "source": [
        "########################################\n",
        "# それぞれが最適化したパラメータで、各モデルの性能比較を行う。\n",
        "\n",
        "# モデルを読み込み\n",
        "from src.control_model import random_model, popular_model\n",
        "from surprise import SVD  # matrix factorization\n",
        "from pyfm.pylibfm import FM # factorization machine\n",
        "from src.DNN_recommender import RFNN # Re-FNN\n",
        "from src.DNN_recommender import R_Wide_and_Deep # Re-FNN\n",
        "\n",
        "# I/F統一用のラッパー\n",
        "from src.surprise_algo_wrapper import surprise_algo_wrapper \n",
        "from src.pyfm_model_wrapper import pyfm_model_wrapper\n",
        "from src.keras_model_wrapper import keras_model_wrapper \n",
        "\n",
        "max_user, max_item = X[:,0].max()+1, X[:,1].max()+1\n",
        "\n",
        "# 以下がグリッドサーチによってチューニングされた変数とする。\n",
        "best_models = {\n",
        "    \"random\" : random_model() ,\n",
        "    \"popular\" : popular_model(),\n",
        "    \"svd\" : surprise_algo_wrapper(SVD(n_factors=8,  reg_all=0.01)),\n",
        "    \"fm\"  : pyfm_model_wrapper(FM(num_factors=8, num_iter=5, reg_0=0.0, reg_w=0.01, reg_v=0.01, validation_size=0.01, task='regression')),\n",
        "    \"rfnn\" : keras_model_wrapper(RFNN, dict(max_user=max_user, max_item=max_item, embedding_size=8, dnn_hidden_units=(64), l2_reg=0.01)),\n",
        "    \"rmd\" : keras_model_wrapper(R_Wide_and_Deep, dict(max_user=max_user, max_item=max_item, embedding_size=8, dnn_hidden_units=(64), l2_reg=0.01)),\n",
        "}\n",
        "\n",
        "# それぞれのクロスバリデーションの結果を取得する。\n",
        "from src.evaluation import cv\n",
        "k_hold = 5\n",
        "results = {'total_mean':[], 'metrics_by_labeled_user':[], 'metrics_by_labeled_item':[], 'metrics_by_labeled_user_item':[]}\n",
        "\n",
        "for name, model in best_models.items():\n",
        "    print(f\"==== {name} ===\")\n",
        "    _result = cv(model, X, y, k_hold=k_hold, need_hit=True, seed=999)\n",
        "    \n",
        "    # result of total_mean\n",
        "    _dict = {k:v for k,v in _result['total_mean'].items() if k not in results}\n",
        "    _df = pd.DataFrame(_dict, index=[1])\n",
        "    _df['model'] = name\n",
        "    results['total_mean'].append(_df)\n",
        "    \n",
        "    # result of metrics_by_labeled_*\n",
        "    for key in [key for key in results if key not in ('total_mean')]:\n",
        "        _df = _result['total_mean'][key]\n",
        "        _df['model'] = name\n",
        "        results[key].append(_df)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==== rfnn ===\n",
            "k_hold = 1/5\n",
            "Train on 70586 samples\n",
            "Epoch 1/5\n",
            "70586/70586 [==============================] - 8s 111us/sample - loss: 3.0155\n",
            "Epoch 2/5\n",
            "70586/70586 [==============================] - 7s 98us/sample - loss: 1.0945\n",
            "Epoch 3/5\n",
            "70586/70586 [==============================] - 7s 98us/sample - loss: 1.0192\n",
            "Epoch 4/5\n",
            "70586/70586 [==============================] - 7s 97us/sample - loss: 1.0069\n",
            "Epoch 5/5\n",
            "70586/70586 [==============================] - 7s 97us/sample - loss: 1.0049\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoIzDV58JHct",
        "colab_type": "code",
        "outputId": "1293e6ef-a7d2-4402-a985-e5516d273e6b",
        "colab": {}
      },
      "source": [
        "# cross validation の結果をresults_dfに整理して、pickleとして保存する。\n",
        "results_df = {}\n",
        "for name, df_list in results.items():\n",
        "    results_df[name] = pd.concat(df_list, axis=0)\n",
        "\n",
        "# pickle として保存しておく。\n",
        "import pickle\n",
        "with open('output/results_df.pickle', 'wb') as f:\n",
        "    pickle.dump(results_df, f)\n",
        "\n",
        "print('以下の結果が、results_dfには格納されている。')    \n",
        "print(results_df.keys())\n",
        "\n",
        "# 例えば、itemのsparse度合いごとの精度は以下の通りである。\n",
        "results_df['metrics_by_labeled_item']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "以下の結果が、results_dfには格納されている。\n",
            "dict_keys(['total_mean', 'metrics_by_labeled_user', 'metrics_by_labeled_item', 'metrics_by_labeled_user_item'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abs_error</th>\n",
              "      <th>hit_top_5</th>\n",
              "      <th>hit_top_10</th>\n",
              "      <th>hit_top_20</th>\n",
              "      <th>hit_top_30</th>\n",
              "      <th>hit_top_40</th>\n",
              "      <th>hit_top_50</th>\n",
              "      <th>hit_top_100</th>\n",
              "      <th>n_sample</th>\n",
              "      <th>model</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>labeled_item</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>000_(0.0, 0.0)</th>\n",
              "      <td>1.478892</td>\n",
              "      <td>0.005813</td>\n",
              "      <td>0.009634</td>\n",
              "      <td>0.019635</td>\n",
              "      <td>0.027905</td>\n",
              "      <td>0.039546</td>\n",
              "      <td>0.048369</td>\n",
              "      <td>0.101407</td>\n",
              "      <td>7378.6</td>\n",
              "      <td>random</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>001_(0.0, 10.0]</th>\n",
              "      <td>1.489238</td>\n",
              "      <td>0.004561</td>\n",
              "      <td>0.008897</td>\n",
              "      <td>0.018949</td>\n",
              "      <td>0.030254</td>\n",
              "      <td>0.039215</td>\n",
              "      <td>0.048178</td>\n",
              "      <td>0.096844</td>\n",
              "      <td>14535.0</td>\n",
              "      <td>random</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>002_(10.0, 20.0]</th>\n",
              "      <td>1.504947</td>\n",
              "      <td>0.007122</td>\n",
              "      <td>0.014648</td>\n",
              "      <td>0.025702</td>\n",
              "      <td>0.035321</td>\n",
              "      <td>0.047201</td>\n",
              "      <td>0.056004</td>\n",
              "      <td>0.105461</td>\n",
              "      <td>3157.0</td>\n",
              "      <td>random</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>003_(20.0, 30.0]</th>\n",
              "      <td>1.530517</td>\n",
              "      <td>0.003030</td>\n",
              "      <td>0.009746</td>\n",
              "      <td>0.020410</td>\n",
              "      <td>0.030430</td>\n",
              "      <td>0.041167</td>\n",
              "      <td>0.051120</td>\n",
              "      <td>0.104941</td>\n",
              "      <td>1807.6</td>\n",
              "      <td>random</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>004_(30.0, 40.0]</th>\n",
              "      <td>1.506425</td>\n",
              "      <td>0.005075</td>\n",
              "      <td>0.009346</td>\n",
              "      <td>0.019306</td>\n",
              "      <td>0.025195</td>\n",
              "      <td>0.037061</td>\n",
              "      <td>0.051639</td>\n",
              "      <td>0.102092</td>\n",
              "      <td>1103.6</td>\n",
              "      <td>random</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>005_(40.0, 50.0]</th>\n",
              "      <td>1.522377</td>\n",
              "      <td>0.005777</td>\n",
              "      <td>0.014975</td>\n",
              "      <td>0.022794</td>\n",
              "      <td>0.037931</td>\n",
              "      <td>0.061385</td>\n",
              "      <td>0.075630</td>\n",
              "      <td>0.132244</td>\n",
              "      <td>635.6</td>\n",
              "      <td>random</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>006_(50.0, inf]</th>\n",
              "      <td>1.528199</td>\n",
              "      <td>0.005674</td>\n",
              "      <td>0.007921</td>\n",
              "      <td>0.019139</td>\n",
              "      <td>0.029193</td>\n",
              "      <td>0.037334</td>\n",
              "      <td>0.046085</td>\n",
              "      <td>0.097632</td>\n",
              "      <td>1632.6</td>\n",
              "      <td>random</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000_(0.0, 0.0)</th>\n",
              "      <td>1.067118</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006226</td>\n",
              "      <td>0.051836</td>\n",
              "      <td>0.134094</td>\n",
              "      <td>0.218701</td>\n",
              "      <td>0.261904</td>\n",
              "      <td>0.464975</td>\n",
              "      <td>7378.6</td>\n",
              "      <td>popular</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>001_(0.0, 10.0]</th>\n",
              "      <td>1.179187</td>\n",
              "      <td>0.083216</td>\n",
              "      <td>0.180353</td>\n",
              "      <td>0.317738</td>\n",
              "      <td>0.437431</td>\n",
              "      <td>0.506073</td>\n",
              "      <td>0.538934</td>\n",
              "      <td>0.694455</td>\n",
              "      <td>14535.0</td>\n",
              "      <td>popular</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>002_(10.0, 20.0]</th>\n",
              "      <td>1.194007</td>\n",
              "      <td>0.119831</td>\n",
              "      <td>0.211444</td>\n",
              "      <td>0.362333</td>\n",
              "      <td>0.501210</td>\n",
              "      <td>0.563075</td>\n",
              "      <td>0.595864</td>\n",
              "      <td>0.725390</td>\n",
              "      <td>3157.0</td>\n",
              "      <td>popular</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>003_(20.0, 30.0]</th>\n",
              "      <td>1.203371</td>\n",
              "      <td>0.200299</td>\n",
              "      <td>0.332052</td>\n",
              "      <td>0.435592</td>\n",
              "      <td>0.557669</td>\n",
              "      <td>0.615215</td>\n",
              "      <td>0.656536</td>\n",
              "      <td>0.784749</td>\n",
              "      <td>1807.6</td>\n",
              "      <td>popular</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>004_(30.0, 40.0]</th>\n",
              "      <td>1.176878</td>\n",
              "      <td>0.177040</td>\n",
              "      <td>0.283173</td>\n",
              "      <td>0.452337</td>\n",
              "      <td>0.528854</td>\n",
              "      <td>0.604129</td>\n",
              "      <td>0.653420</td>\n",
              "      <td>0.781217</td>\n",
              "      <td>1103.6</td>\n",
              "      <td>popular</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>005_(40.0, 50.0]</th>\n",
              "      <td>1.184719</td>\n",
              "      <td>0.210769</td>\n",
              "      <td>0.331703</td>\n",
              "      <td>0.550435</td>\n",
              "      <td>0.583374</td>\n",
              "      <td>0.641980</td>\n",
              "      <td>0.666069</td>\n",
              "      <td>0.798570</td>\n",
              "      <td>635.6</td>\n",
              "      <td>popular</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>006_(50.0, inf]</th>\n",
              "      <td>1.262375</td>\n",
              "      <td>0.275205</td>\n",
              "      <td>0.374420</td>\n",
              "      <td>0.530814</td>\n",
              "      <td>0.617339</td>\n",
              "      <td>0.671167</td>\n",
              "      <td>0.704485</td>\n",
              "      <td>0.819076</td>\n",
              "      <td>1632.6</td>\n",
              "      <td>popular</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000_(0.0, 0.0)</th>\n",
              "      <td>0.649786</td>\n",
              "      <td>0.021461</td>\n",
              "      <td>0.041755</td>\n",
              "      <td>0.086743</td>\n",
              "      <td>0.159058</td>\n",
              "      <td>0.225142</td>\n",
              "      <td>0.286176</td>\n",
              "      <td>0.491237</td>\n",
              "      <td>7378.6</td>\n",
              "      <td>svd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>001_(0.0, 10.0]</th>\n",
              "      <td>0.681532</td>\n",
              "      <td>0.074051</td>\n",
              "      <td>0.131044</td>\n",
              "      <td>0.232884</td>\n",
              "      <td>0.326546</td>\n",
              "      <td>0.396815</td>\n",
              "      <td>0.452544</td>\n",
              "      <td>0.615678</td>\n",
              "      <td>14535.0</td>\n",
              "      <td>svd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>002_(10.0, 20.0]</th>\n",
              "      <td>0.683809</td>\n",
              "      <td>0.101293</td>\n",
              "      <td>0.171189</td>\n",
              "      <td>0.281147</td>\n",
              "      <td>0.371066</td>\n",
              "      <td>0.437440</td>\n",
              "      <td>0.493604</td>\n",
              "      <td>0.650670</td>\n",
              "      <td>3157.0</td>\n",
              "      <td>svd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>003_(20.0, 30.0]</th>\n",
              "      <td>0.670406</td>\n",
              "      <td>0.141293</td>\n",
              "      <td>0.205118</td>\n",
              "      <td>0.312912</td>\n",
              "      <td>0.396529</td>\n",
              "      <td>0.479099</td>\n",
              "      <td>0.544581</td>\n",
              "      <td>0.688672</td>\n",
              "      <td>1807.6</td>\n",
              "      <td>svd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>004_(30.0, 40.0]</th>\n",
              "      <td>0.670319</td>\n",
              "      <td>0.098320</td>\n",
              "      <td>0.197014</td>\n",
              "      <td>0.331017</td>\n",
              "      <td>0.441682</td>\n",
              "      <td>0.529623</td>\n",
              "      <td>0.589896</td>\n",
              "      <td>0.725671</td>\n",
              "      <td>1103.6</td>\n",
              "      <td>svd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>005_(40.0, 50.0]</th>\n",
              "      <td>0.670033</td>\n",
              "      <td>0.139547</td>\n",
              "      <td>0.244490</td>\n",
              "      <td>0.417024</td>\n",
              "      <td>0.499889</td>\n",
              "      <td>0.523723</td>\n",
              "      <td>0.566108</td>\n",
              "      <td>0.682988</td>\n",
              "      <td>635.6</td>\n",
              "      <td>svd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>006_(50.0, inf]</th>\n",
              "      <td>0.684635</td>\n",
              "      <td>0.117525</td>\n",
              "      <td>0.178858</td>\n",
              "      <td>0.290411</td>\n",
              "      <td>0.385652</td>\n",
              "      <td>0.462018</td>\n",
              "      <td>0.510290</td>\n",
              "      <td>0.631779</td>\n",
              "      <td>1632.6</td>\n",
              "      <td>svd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000_(0.0, 0.0)</th>\n",
              "      <td>0.661337</td>\n",
              "      <td>0.016448</td>\n",
              "      <td>0.039401</td>\n",
              "      <td>0.080283</td>\n",
              "      <td>0.154171</td>\n",
              "      <td>0.221484</td>\n",
              "      <td>0.283216</td>\n",
              "      <td>0.495092</td>\n",
              "      <td>7378.6</td>\n",
              "      <td>fm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>001_(0.0, 10.0]</th>\n",
              "      <td>0.691594</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.128769</td>\n",
              "      <td>0.232734</td>\n",
              "      <td>0.323786</td>\n",
              "      <td>0.396645</td>\n",
              "      <td>0.454136</td>\n",
              "      <td>0.612149</td>\n",
              "      <td>14535.0</td>\n",
              "      <td>fm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>002_(10.0, 20.0]</th>\n",
              "      <td>0.693755</td>\n",
              "      <td>0.094010</td>\n",
              "      <td>0.147427</td>\n",
              "      <td>0.284918</td>\n",
              "      <td>0.371125</td>\n",
              "      <td>0.442910</td>\n",
              "      <td>0.485293</td>\n",
              "      <td>0.649742</td>\n",
              "      <td>3157.0</td>\n",
              "      <td>fm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>003_(20.0, 30.0]</th>\n",
              "      <td>0.676645</td>\n",
              "      <td>0.165553</td>\n",
              "      <td>0.232051</td>\n",
              "      <td>0.320077</td>\n",
              "      <td>0.392908</td>\n",
              "      <td>0.472656</td>\n",
              "      <td>0.550562</td>\n",
              "      <td>0.679582</td>\n",
              "      <td>1807.6</td>\n",
              "      <td>fm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>004_(30.0, 40.0]</th>\n",
              "      <td>0.679053</td>\n",
              "      <td>0.095029</td>\n",
              "      <td>0.181035</td>\n",
              "      <td>0.350202</td>\n",
              "      <td>0.457832</td>\n",
              "      <td>0.536593</td>\n",
              "      <td>0.593503</td>\n",
              "      <td>0.716793</td>\n",
              "      <td>1103.6</td>\n",
              "      <td>fm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>005_(40.0, 50.0]</th>\n",
              "      <td>0.680572</td>\n",
              "      <td>0.141941</td>\n",
              "      <td>0.258076</td>\n",
              "      <td>0.382699</td>\n",
              "      <td>0.481761</td>\n",
              "      <td>0.526664</td>\n",
              "      <td>0.571304</td>\n",
              "      <td>0.669617</td>\n",
              "      <td>635.6</td>\n",
              "      <td>fm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>006_(50.0, inf]</th>\n",
              "      <td>0.692756</td>\n",
              "      <td>0.133692</td>\n",
              "      <td>0.203272</td>\n",
              "      <td>0.292972</td>\n",
              "      <td>0.392747</td>\n",
              "      <td>0.469261</td>\n",
              "      <td>0.512978</td>\n",
              "      <td>0.637258</td>\n",
              "      <td>1632.6</td>\n",
              "      <td>fm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000_(0.0, 0.0)</th>\n",
              "      <td>0.677997</td>\n",
              "      <td>0.022318</td>\n",
              "      <td>0.041250</td>\n",
              "      <td>0.118403</td>\n",
              "      <td>0.188666</td>\n",
              "      <td>0.252751</td>\n",
              "      <td>0.287772</td>\n",
              "      <td>0.430794</td>\n",
              "      <td>7378.6</td>\n",
              "      <td>rfnn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>001_(0.0, 10.0]</th>\n",
              "      <td>0.716295</td>\n",
              "      <td>0.118808</td>\n",
              "      <td>0.175204</td>\n",
              "      <td>0.305899</td>\n",
              "      <td>0.390473</td>\n",
              "      <td>0.445465</td>\n",
              "      <td>0.479859</td>\n",
              "      <td>0.590873</td>\n",
              "      <td>14535.0</td>\n",
              "      <td>rfnn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>002_(10.0, 20.0]</th>\n",
              "      <td>0.723996</td>\n",
              "      <td>0.156911</td>\n",
              "      <td>0.238044</td>\n",
              "      <td>0.374371</td>\n",
              "      <td>0.431967</td>\n",
              "      <td>0.469642</td>\n",
              "      <td>0.503713</td>\n",
              "      <td>0.624729</td>\n",
              "      <td>3157.0</td>\n",
              "      <td>rfnn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>003_(20.0, 30.0]</th>\n",
              "      <td>0.710054</td>\n",
              "      <td>0.193276</td>\n",
              "      <td>0.267326</td>\n",
              "      <td>0.426781</td>\n",
              "      <td>0.521800</td>\n",
              "      <td>0.585449</td>\n",
              "      <td>0.600970</td>\n",
              "      <td>0.688423</td>\n",
              "      <td>1807.6</td>\n",
              "      <td>rfnn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>004_(30.0, 40.0]</th>\n",
              "      <td>0.710004</td>\n",
              "      <td>0.181370</td>\n",
              "      <td>0.348371</td>\n",
              "      <td>0.465106</td>\n",
              "      <td>0.521829</td>\n",
              "      <td>0.575785</td>\n",
              "      <td>0.631121</td>\n",
              "      <td>0.736057</td>\n",
              "      <td>1103.6</td>\n",
              "      <td>rfnn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>005_(40.0, 50.0]</th>\n",
              "      <td>0.715749</td>\n",
              "      <td>0.257836</td>\n",
              "      <td>0.361837</td>\n",
              "      <td>0.499082</td>\n",
              "      <td>0.531883</td>\n",
              "      <td>0.621338</td>\n",
              "      <td>0.627636</td>\n",
              "      <td>0.662729</td>\n",
              "      <td>635.6</td>\n",
              "      <td>rfnn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>006_(50.0, inf]</th>\n",
              "      <td>0.724166</td>\n",
              "      <td>0.208415</td>\n",
              "      <td>0.315869</td>\n",
              "      <td>0.399002</td>\n",
              "      <td>0.480814</td>\n",
              "      <td>0.527572</td>\n",
              "      <td>0.551505</td>\n",
              "      <td>0.631274</td>\n",
              "      <td>1632.6</td>\n",
              "      <td>rfnn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000_(0.0, 0.0)</th>\n",
              "      <td>0.678332</td>\n",
              "      <td>0.020742</td>\n",
              "      <td>0.041250</td>\n",
              "      <td>0.119268</td>\n",
              "      <td>0.190383</td>\n",
              "      <td>0.251674</td>\n",
              "      <td>0.285855</td>\n",
              "      <td>0.430767</td>\n",
              "      <td>7378.6</td>\n",
              "      <td>rmd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>001_(0.0, 10.0]</th>\n",
              "      <td>0.716798</td>\n",
              "      <td>0.112236</td>\n",
              "      <td>0.175935</td>\n",
              "      <td>0.308658</td>\n",
              "      <td>0.391647</td>\n",
              "      <td>0.446453</td>\n",
              "      <td>0.480169</td>\n",
              "      <td>0.589582</td>\n",
              "      <td>14535.0</td>\n",
              "      <td>rmd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>002_(10.0, 20.0]</th>\n",
              "      <td>0.724555</td>\n",
              "      <td>0.171483</td>\n",
              "      <td>0.238044</td>\n",
              "      <td>0.373334</td>\n",
              "      <td>0.435474</td>\n",
              "      <td>0.470591</td>\n",
              "      <td>0.502053</td>\n",
              "      <td>0.620142</td>\n",
              "      <td>3157.0</td>\n",
              "      <td>rmd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>003_(20.0, 30.0]</th>\n",
              "      <td>0.710706</td>\n",
              "      <td>0.193276</td>\n",
              "      <td>0.267326</td>\n",
              "      <td>0.433493</td>\n",
              "      <td>0.516758</td>\n",
              "      <td>0.585449</td>\n",
              "      <td>0.606339</td>\n",
              "      <td>0.689161</td>\n",
              "      <td>1807.6</td>\n",
              "      <td>rmd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>004_(30.0, 40.0]</th>\n",
              "      <td>0.710599</td>\n",
              "      <td>0.181370</td>\n",
              "      <td>0.348371</td>\n",
              "      <td>0.465106</td>\n",
              "      <td>0.521829</td>\n",
              "      <td>0.575785</td>\n",
              "      <td>0.630140</td>\n",
              "      <td>0.736057</td>\n",
              "      <td>1103.6</td>\n",
              "      <td>rmd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>005_(40.0, 50.0]</th>\n",
              "      <td>0.716545</td>\n",
              "      <td>0.257836</td>\n",
              "      <td>0.361837</td>\n",
              "      <td>0.499082</td>\n",
              "      <td>0.531883</td>\n",
              "      <td>0.621338</td>\n",
              "      <td>0.627636</td>\n",
              "      <td>0.662729</td>\n",
              "      <td>635.6</td>\n",
              "      <td>rmd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>006_(50.0, inf]</th>\n",
              "      <td>0.724781</td>\n",
              "      <td>0.208415</td>\n",
              "      <td>0.315869</td>\n",
              "      <td>0.399002</td>\n",
              "      <td>0.485374</td>\n",
              "      <td>0.526344</td>\n",
              "      <td>0.554623</td>\n",
              "      <td>0.632755</td>\n",
              "      <td>1632.6</td>\n",
              "      <td>rmd</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  abs_error  hit_top_5  hit_top_10  hit_top_20  hit_top_30  \\\n",
              "labeled_item                                                                 \n",
              "000_(0.0, 0.0)     1.478892   0.005813    0.009634    0.019635    0.027905   \n",
              "001_(0.0, 10.0]    1.489238   0.004561    0.008897    0.018949    0.030254   \n",
              "002_(10.0, 20.0]   1.504947   0.007122    0.014648    0.025702    0.035321   \n",
              "003_(20.0, 30.0]   1.530517   0.003030    0.009746    0.020410    0.030430   \n",
              "004_(30.0, 40.0]   1.506425   0.005075    0.009346    0.019306    0.025195   \n",
              "005_(40.0, 50.0]   1.522377   0.005777    0.014975    0.022794    0.037931   \n",
              "006_(50.0, inf]    1.528199   0.005674    0.007921    0.019139    0.029193   \n",
              "000_(0.0, 0.0)     1.067118   0.000000    0.006226    0.051836    0.134094   \n",
              "001_(0.0, 10.0]    1.179187   0.083216    0.180353    0.317738    0.437431   \n",
              "002_(10.0, 20.0]   1.194007   0.119831    0.211444    0.362333    0.501210   \n",
              "003_(20.0, 30.0]   1.203371   0.200299    0.332052    0.435592    0.557669   \n",
              "004_(30.0, 40.0]   1.176878   0.177040    0.283173    0.452337    0.528854   \n",
              "005_(40.0, 50.0]   1.184719   0.210769    0.331703    0.550435    0.583374   \n",
              "006_(50.0, inf]    1.262375   0.275205    0.374420    0.530814    0.617339   \n",
              "000_(0.0, 0.0)     0.649786   0.021461    0.041755    0.086743    0.159058   \n",
              "001_(0.0, 10.0]    0.681532   0.074051    0.131044    0.232884    0.326546   \n",
              "002_(10.0, 20.0]   0.683809   0.101293    0.171189    0.281147    0.371066   \n",
              "003_(20.0, 30.0]   0.670406   0.141293    0.205118    0.312912    0.396529   \n",
              "004_(30.0, 40.0]   0.670319   0.098320    0.197014    0.331017    0.441682   \n",
              "005_(40.0, 50.0]   0.670033   0.139547    0.244490    0.417024    0.499889   \n",
              "006_(50.0, inf]    0.684635   0.117525    0.178858    0.290411    0.385652   \n",
              "000_(0.0, 0.0)     0.661337   0.016448    0.039401    0.080283    0.154171   \n",
              "001_(0.0, 10.0]    0.691594   0.068900    0.128769    0.232734    0.323786   \n",
              "002_(10.0, 20.0]   0.693755   0.094010    0.147427    0.284918    0.371125   \n",
              "003_(20.0, 30.0]   0.676645   0.165553    0.232051    0.320077    0.392908   \n",
              "004_(30.0, 40.0]   0.679053   0.095029    0.181035    0.350202    0.457832   \n",
              "005_(40.0, 50.0]   0.680572   0.141941    0.258076    0.382699    0.481761   \n",
              "006_(50.0, inf]    0.692756   0.133692    0.203272    0.292972    0.392747   \n",
              "000_(0.0, 0.0)     0.677997   0.022318    0.041250    0.118403    0.188666   \n",
              "001_(0.0, 10.0]    0.716295   0.118808    0.175204    0.305899    0.390473   \n",
              "002_(10.0, 20.0]   0.723996   0.156911    0.238044    0.374371    0.431967   \n",
              "003_(20.0, 30.0]   0.710054   0.193276    0.267326    0.426781    0.521800   \n",
              "004_(30.0, 40.0]   0.710004   0.181370    0.348371    0.465106    0.521829   \n",
              "005_(40.0, 50.0]   0.715749   0.257836    0.361837    0.499082    0.531883   \n",
              "006_(50.0, inf]    0.724166   0.208415    0.315869    0.399002    0.480814   \n",
              "000_(0.0, 0.0)     0.678332   0.020742    0.041250    0.119268    0.190383   \n",
              "001_(0.0, 10.0]    0.716798   0.112236    0.175935    0.308658    0.391647   \n",
              "002_(10.0, 20.0]   0.724555   0.171483    0.238044    0.373334    0.435474   \n",
              "003_(20.0, 30.0]   0.710706   0.193276    0.267326    0.433493    0.516758   \n",
              "004_(30.0, 40.0]   0.710599   0.181370    0.348371    0.465106    0.521829   \n",
              "005_(40.0, 50.0]   0.716545   0.257836    0.361837    0.499082    0.531883   \n",
              "006_(50.0, inf]    0.724781   0.208415    0.315869    0.399002    0.485374   \n",
              "\n",
              "                  hit_top_40  hit_top_50  hit_top_100  n_sample    model  \n",
              "labeled_item                                                              \n",
              "000_(0.0, 0.0)      0.039546    0.048369     0.101407    7378.6   random  \n",
              "001_(0.0, 10.0]     0.039215    0.048178     0.096844   14535.0   random  \n",
              "002_(10.0, 20.0]    0.047201    0.056004     0.105461    3157.0   random  \n",
              "003_(20.0, 30.0]    0.041167    0.051120     0.104941    1807.6   random  \n",
              "004_(30.0, 40.0]    0.037061    0.051639     0.102092    1103.6   random  \n",
              "005_(40.0, 50.0]    0.061385    0.075630     0.132244     635.6   random  \n",
              "006_(50.0, inf]     0.037334    0.046085     0.097632    1632.6   random  \n",
              "000_(0.0, 0.0)      0.218701    0.261904     0.464975    7378.6  popular  \n",
              "001_(0.0, 10.0]     0.506073    0.538934     0.694455   14535.0  popular  \n",
              "002_(10.0, 20.0]    0.563075    0.595864     0.725390    3157.0  popular  \n",
              "003_(20.0, 30.0]    0.615215    0.656536     0.784749    1807.6  popular  \n",
              "004_(30.0, 40.0]    0.604129    0.653420     0.781217    1103.6  popular  \n",
              "005_(40.0, 50.0]    0.641980    0.666069     0.798570     635.6  popular  \n",
              "006_(50.0, inf]     0.671167    0.704485     0.819076    1632.6  popular  \n",
              "000_(0.0, 0.0)      0.225142    0.286176     0.491237    7378.6      svd  \n",
              "001_(0.0, 10.0]     0.396815    0.452544     0.615678   14535.0      svd  \n",
              "002_(10.0, 20.0]    0.437440    0.493604     0.650670    3157.0      svd  \n",
              "003_(20.0, 30.0]    0.479099    0.544581     0.688672    1807.6      svd  \n",
              "004_(30.0, 40.0]    0.529623    0.589896     0.725671    1103.6      svd  \n",
              "005_(40.0, 50.0]    0.523723    0.566108     0.682988     635.6      svd  \n",
              "006_(50.0, inf]     0.462018    0.510290     0.631779    1632.6      svd  \n",
              "000_(0.0, 0.0)      0.221484    0.283216     0.495092    7378.6       fm  \n",
              "001_(0.0, 10.0]     0.396645    0.454136     0.612149   14535.0       fm  \n",
              "002_(10.0, 20.0]    0.442910    0.485293     0.649742    3157.0       fm  \n",
              "003_(20.0, 30.0]    0.472656    0.550562     0.679582    1807.6       fm  \n",
              "004_(30.0, 40.0]    0.536593    0.593503     0.716793    1103.6       fm  \n",
              "005_(40.0, 50.0]    0.526664    0.571304     0.669617     635.6       fm  \n",
              "006_(50.0, inf]     0.469261    0.512978     0.637258    1632.6       fm  \n",
              "000_(0.0, 0.0)      0.252751    0.287772     0.430794    7378.6     rfnn  \n",
              "001_(0.0, 10.0]     0.445465    0.479859     0.590873   14535.0     rfnn  \n",
              "002_(10.0, 20.0]    0.469642    0.503713     0.624729    3157.0     rfnn  \n",
              "003_(20.0, 30.0]    0.585449    0.600970     0.688423    1807.6     rfnn  \n",
              "004_(30.0, 40.0]    0.575785    0.631121     0.736057    1103.6     rfnn  \n",
              "005_(40.0, 50.0]    0.621338    0.627636     0.662729     635.6     rfnn  \n",
              "006_(50.0, inf]     0.527572    0.551505     0.631274    1632.6     rfnn  \n",
              "000_(0.0, 0.0)      0.251674    0.285855     0.430767    7378.6      rmd  \n",
              "001_(0.0, 10.0]     0.446453    0.480169     0.589582   14535.0      rmd  \n",
              "002_(10.0, 20.0]    0.470591    0.502053     0.620142    3157.0      rmd  \n",
              "003_(20.0, 30.0]    0.585449    0.606339     0.689161    1807.6      rmd  \n",
              "004_(30.0, 40.0]    0.575785    0.630140     0.736057    1103.6      rmd  \n",
              "005_(40.0, 50.0]    0.621338    0.627636     0.662729     635.6      rmd  \n",
              "006_(50.0, inf]     0.526344    0.554623     0.632755    1632.6      rmd  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXwCpmZ2JHcw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# bisualizationを行う。\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_bar(a='metrics_by_labeled_item', b='hit_top_50', c=['labeled_item', 'model']):\n",
        "    _df = results_df[a].reset_index()\n",
        "    _df = _df.set_index(c)\n",
        "    _df[b].plot(kind='bar')    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AixdndBJJHc0",
        "colab_type": "code",
        "outputId": "74a07051-8bec-459d-dde8-14a9c05c1eed",
        "colab": {}
      },
      "source": [
        "plot_bar(a='total_mean', b='hit_top_50_precision', c=['model'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "640K1axoJHc8",
        "colab_type": "code",
        "outputId": "292e26c7-bdf0-468c-f916-c1b45f578521",
        "colab": {}
      },
      "source": [
        "plot_bar(a='metrics_by_labeled_item', b='hit_top_50', c=['labeled_item', 'model'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-D1q-SOcJHc-",
        "colab_type": "code",
        "outputId": "69d434e5-8861-4290-a55d-fa8dd7574d88",
        "colab": {}
      },
      "source": [
        "plot_bar(a='metrics_by_labeled_user', b='hit_top_50', c=['labeled_user', 'model'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAGHCAYAAABLUhLnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzsnXm4HUXRuN8iLFF2JKwBEhQRlD0EFD4RBQXBwKcsQRBwg5+yqZ9CVGRzA1T8+BQQRJRFNkUhQpDNACpbwhZMIBBChIhIRHAFEajfH9Vz79y5M91zlptz71Dv85zn3jk9XdM9Z06d7urqKlFVHMdxnGaxRK8b4DiO43QfV+6O4zgNxJW74zhOA3Hl7jiO00BcuTuO4zQQV+6O4zgNxJW74zhOA3Hl7jiO00BcuTuO4zSQJXt14VVXXVXHjRvXq8s7juOMSO6+++4/q+qY1Hk9U+7jxo1j5syZvbq84zjOiEREfl/nPDfLOI7jNBBX7o7jOA3ElbvjOE4DceXuOI7TQFy5O47jNBBX7o7jOA3ElbvjOE4DceXuOI7TQHq2ickxxk25ZsDxgpN361FLHMdpEj5ydxzHaSCu3B3HcRqIK3fHcZwG4srdcRyngdRS7iKyi4jMFZF5IjKlpHxdEZkuIveKyCwReW/3m+o4juPUJancRWQUcAawK7AxsJ+IbFw47VjgclXdApgMnNnthjqO4zj1qTNynwjMU9X5qvoicCmwR+EcBVYI/68IPNm9JjqO4zitUke5rw08kTteGN7LcwJwgIgsBKYBR5QJEpFDRGSmiMxctGhRG811HMdx6lBHuUvJe1o43g/4kaqOBd4LXCgig2Sr6jmqOkFVJ4wZk8wS5TiO47RJHeW+EFgndzyWwWaXjwKXA6jq7cBoYNVuNNBxHMdpnTrKfQawgYiMF5GlsQXTqYVzHgfeBSAiG2HK3e0ujuM4PSKp3FX1JeBw4DrgQcwrZraInCQik8Jp/wN8XETuBy4BDlbVounGcRzHWUzUChymqtOwhdL8e8fl/p8DbNfdpjmO4zjt4jtUHcdxGogrd8dxnAbiyt1xHKeBuHJ3HMdpIK7cHcdxGogrd8dxnAbiyt1xHKeBuHJ3HMdpIK7cHcdxGogrd8dxnAbiyt1xHKeBuHJ3HMdpIK7cHcdxGogrd8dxnAbiyt1xHKeBuHJ3HMdpILWUu4jsIiJzRWSeiEwpKf+2iNwXXg+LyHPdb6rjOI5Tl2QmJhEZBZwB7Iwly54hIlND9iUAVPXTufOPALYYgrY6juM4Nakzcp8IzFPV+ar6InApsEfk/P2wPKqO4zhOj6ij3NcGnsgdLwzvDUJE1gPGA7+qKD9ERGaKyMxFixa12lbHcRynJnWUu5S8pxXnTgZ+qqovlxWq6jmqOkFVJ4wZM6ZuGx3HcZwWqaPcFwLr5I7HAk9WnDsZN8k4juP0nDrKfQawgYiMF5GlMQU+tXiSiGwIrAzc3t0mOo7jOK2SVO6q+hJwOHAd8CBwuarOFpGTRGRS7tT9gEtVtcpk4ziO4ywmkq6QAKo6DZhWeO+4wvEJ3WuW4ziO0wm+Q9VxHKeBuHJ3HMdpILXMMo7TLuOmXDPgeMHJu/WoJd2nyX0D799Ix0fujuM4DcSVu+M4TgNx5e44jtNAXLk7juM0EFfujuM4DcSVu+M4TgNx5e44jtNAXLk7juM0EFfujuM4DcSVu+M4TgNx5e44jtNAXLk7juM0EFfujuM4DaSWcheRXURkrojME5EpFefsIyJzRGS2iFzc3WY6juM4rZAM+Ssio4AzgJ2xZNkzRGSqqs7JnbMB8HlgO1V9VkRWG6oGO47jOGnqjNwnAvNUdb6qvghcCuxROOfjwBmq+iyAqj7d3WY6juM4rVBHua8NPJE7Xhjey/NG4I0i8lsRuUNEdikTJCKHiMhMEZm5aNGi9lrsOI7jJKmj3KXkPS0cLwlsALwD2A84V0RWGlRJ9RxVnaCqE8aMGdNqWx3HcZya1FHuC4F1csdjgSdLzrlKVf+jqo8BczFl7ziO4/SAOsp9BrCBiIwXkaWBycDUwjlXAjsCiMiqmJlmfjcb6jiO49QnqdxV9SXgcOA64EHgclWdLSInicikcNp1wDMiMgeYDnxOVZ8ZqkY7juM4cZKukACqOg2YVnjvuNz/CnwmvBzHcZwe4ztUHcdxGogrd8dxnAbiyt1xHKeB1LK5O8OXcVOuGXC84OTdetQSx3GGEz5ydxzHaSCu3B3HcRqIK3fHcZwG4jb3Vzlus3ecZuIjd8dxnAbiyt1xHKeBuHJ3HMdpIK7cHcdxGogvqDpRfMHVcUYmPnJ3HMdpID5ybzg+8nacVyc+cnccx2kgtUbuIrILcDowCjhXVU8ulB8MfAP4Q3jru6p6bhfb+arFR97OSKXpz+5w719SuYvIKOAMYGcsEfYMEZmqqnMKp16mqocPQRsdx3GcFqljlpkIzFPV+ar6InApsMfQNstxHMfphDrKfW3gidzxwvBekQ+IyCwR+amIrFMmSEQOEZGZIjJz0aJFbTTXcRzHqUMd5S4l72nh+BfAOFXdFLgROL9MkKqeo6oTVHXCmDFjWmup4ziOU5s6C6oLgfxIfCzwZP4EVX0md/h94JTOm+Y4zquZ4b5g2SlD3b86I/cZwAYiMl5ElgYmA1PzJ4jImrnDScCD3Wui4ziO0yrJkbuqviQihwPXYa6Q56nqbBE5CZipqlOBI0VkEvAS8Bfg4CFss+M4jpOglp+7qk4DphXeOy73/+eBz3e3aY7jOE67ePgBZ1jTdLtrJ4z0ezPS25+i1/1z5e44zoik18pzqOm0f67cnUYznBXAcG6bM/Jx5e6MaJqsIJvcN2foceXuOE5bNP3HZ6T3z0P+Oo7jNBBX7o7jOA3EzTLOq5aRPu1O0fT+OXF85O44jtNAXLk7juM0EFfujuM4DcRt7k5PabJduMl9c4Y/rtydjnAF5jjDEzfLOI7jNBBX7o7jOA3EzTKO8yql6Sa1pvcvRa2Ru4jsIiJzRWSeiEyJnLeXiKiITOheEx3HcZxWSY7cRWQUcAawM5Yse4aITFXVOYXzlgeOBO4cioY6zuLm1T7yc0Y2dUbuE4F5qjpfVV8ELgX2KDnvy8CpwAtdbJ/jOI7TBnWU+9rAE7njheG9PkRkC2AdVb06JkhEDhGRmSIyc9GiRS031nEcx6lHHeUuJe9pX6HIEsC3gf9JCVLVc1R1gqpOGDNmTP1WOo7jOC1RR7kvBNbJHY8FnswdLw+8BbhZRBYA2wJTfVHVcRynd9RxhZwBbCAi44E/AJOBD2aFqvpXYNXsWERuBj6rqjO729SRiS/KOY7TC5Ijd1V9CTgcuA54ELhcVWeLyEkiMmmoG+g4juO0Tq1NTKo6DZhWeO+4inPf0XmzHMdxnE7w8AOO4zgNxJW74zhOA3Hl7jiO00BcuTuO4zQQV+6O4zgNxJW74zhOA3Hl7jiO00BcuTuO4zQQV+6O4zgNxJW74zhOA3Hl7jiO00BcuTuO4zQQV+6O4zgNxJW74zhOA3Hl7jiO00BcuTuO4zSQWspdRHYRkbkiMk9EppSU/z8ReUBE7hOR34jIxt1vquM4jlOXpHIXkVHAGcCuwMbAfiXK+2JV3URVNwdOBU7reksdx3Gc2tQZuU8E5qnqfFV9EbgU2CN/gqr+LXe4LKDda6LjOI7TKnVyqK4NPJE7XghsUzxJRA4DPgMsDbyzTJCIHAIcArDuuuu22lbHcRynJnVG7lLy3qCRuaqeoaqvB44Bji0TpKrnqOoEVZ0wZsyY1lrqOI7j1KaOcl8IrJM7Hgs8GTn/UmDPThrlOI7jdEYd5T4D2EBExovI0sBkYGr+BBHZIHe4G/BI95roOI7jtErS5q6qL4nI4cB1wCjgPFWdLSInATNVdSpwuIjsBPwHeBY4aCgb7TiO48Sps6CKqk4DphXeOy73/1FdbpfjOI7TAb5D1XEcp4G4cnccx2kgrtwdx3EaiCt3x3GcBuLK3XEcp4G4cnccx2kgrtwdx3EaiCt3x3GcBuLK3XEcp4G4cnccx2kgrtwdx3EaiCt3x3GcBuLK3XEcp4G4cnccx2kgrtwdx3EaSC3lLiK7iMhcEZknIlNKyj8jInNEZJaI3CQi63W/qY7jOE5dkspdREYBZwC7AhsD+4nIxoXT7gUmqOqmwE+BU7vdUMdxHKc+dUbuE4F5qjpfVV/EEmDvkT9BVaer6r/C4R1YEm3HcRynR9RR7msDT+SOF4b3qvgocG1ZgYgcIiIzRWTmokWL6rfScRzHaYk6yl1K3tPSE0UOACYA3ygrV9VzVHWCqk4YM2ZM/VY6juM4LVEnQfZCYJ3c8VjgyeJJIrIT8EVgB1X9d3ea5ziO47RDnZH7DGADERkvIksDk4Gp+RNEZAvgbGCSqj7d/WY6juM4rZBU7qr6EnA4cB3wIHC5qs4WkZNEZFI47RvAcsBPROQ+EZlaIc5xHMdZDNQxy6Cq04BphfeOy/2/U5fb5TiO43SA71B1HMdpIK7cHcdxGogrd8dxnAZSy+beS8ZNuWbA8YKTd+tRSxzHcUYOPnJ3HMdpIK7cHcdxGogrd8dxnAbiyt1xHKeBuHJ3HMdpIK7cHcdxGogrd8dxnAbiyt1xHKeBuHJ3HMdpIK7cHcdxGogrd8dxnAbiyt1xHKeB1FLuIrKLiMwVkXkiMqWk/O0ico+IvCQie3W/mY7jOE4rJJW7iIwCzgB2BTYG9hORjQunPQ4cDFzc7QY6juM4rVMn5O9EYJ6qzgcQkUuBPYA52QmquiCUvTIEbXQcx3FapI5ZZm3gidzxwvBey4jIISIyU0RmLlq0qB0RjuM4Tg3qKHcpeU/buZiqnqOqE1R1wpgxY9oR4TiO49SgjnJfCKyTOx4LPDk0zXEcx3G6QR3lPgPYQETGi8jSwGRg6tA2y3Ecx+mEpHJX1ZeAw4HrgAeBy1V1toicJCKTAERkaxFZCOwNnC0is4ey0Y7jOE6cWgmyVXUaMK3w3nG5/2dg5hrHcRxnGOA7VB3HcRqIK3fHcZwG4srdcRyngbhydxzHaSCu3B3HcRpILW+Zkcy4KdcMOF5w8m4tlTuO44xERrxyd+XsOI4zmJ4r95GunEd6+x3HaSY9V+7DHVfejuOMRHxB1XEcp4G4cnccx2kgrtwdx3EaiCt3x3GcBuLK3XEcp4G4cnccx2kgrtwdx3EaSC3lLiK7iMhcEZknIlNKypcRkctC+Z0iMq7bDXUcx3Hqk1TuIjIKOAPYFdgY2E9ENi6c9lHgWVV9A/Bt4JRuN9RxHMepT52R+0RgnqrOV9UXgUuBPQrn7AGcH/7/KfAuEZHuNdNxHMdpBVHV+AkiewG7qOrHwvGHgG1U9fDcOb8L5ywMx4+Gc/5ckHUIcEg43BCYmyteFRhwfgEv9/KhKh/ObfNyLy+Wr6eqYyLnG6oafQF7A+fmjj8EfKdwzmxgbO74UeB1KdkFGTO93Mt7UT6c2+blXp4qr3rVMcssBNbJHY8Fnqw6R0SWBFYE/lJDtuM4jjME1FHuM4ANRGS8iCwNTAamFs6ZChwU/t8L+JWGnxzHcRxn8ZMM+auqL4nI4cB1wCjgPFWdLSInYdOFqcAPgAtFZB42Yp/cRlvO8XIv71H5cG6bl3t5qryU5IKq4ziOM/LwHaqO4zgNxJW74zhOA3Hl7jiO00CGRQ5VEVkWeEFVX+51W7qFiKwGbAesBTwP/A5bgH6lZv0lgM1y9Wer6p9Kzmv73onIyjn5C8ra1q78Tvvfa/k125C8f5G6yc83Jj/V/7rPT6R9r4bPr/TZrtO2Tr47nX72tfvXiwXV0LnJwP7A1sC/gWWARcA0bHV4ReC/GHiDb1TVv4jIW4EDQvmaufJrgIuCvN1L6l+jqrNDGyZE5I8N7RtUH7gWWLpKPrAaMAVYBbgXeBoYDbwReD0WnuFW4P0V7f8NcBiwE/BIuCdZ/X+Fe/Nv4IORe7dq5P5MxTai7Rf6kclfHbgDOAtYI/HZxOT/Hjgi0f9LIvfvWlV9perzwb4Uqfv7XWCHDj7/0ZH2LQyfT9X9O1NVp0favzJwTOTzvSCcM7lC/m3ALpH+3wQsH/pfJv9sbGf4/k39/CLlNwHvofrZvh/7blS17RehzvsrPpvUd+fa8Lm2+9mfqarTqUmvlPst2Ad9FfC73GhjFeBETHE8AlzJwBu8HdbR3wAXAzML5TtiD+ZLQfbdJeXjMXPUgyXl22E/Kk9iD1mZ/D2xD+LqCvmbAIeo6vUl/V4SuBN4Dji9Qv7RhOBrxb0CYURxG/YQnlhy73bEgrw9BJxWIf+LwI+Ak1T1uYL8rcJ9mwEc36b8o4ATVPW8iv5fB7wOOK+i/i6AAg+U3N/tsC/Lx1T1jgr5F2FfrCtL6tf5/EeF8hsq6r8N+Bb2RSu7f1/HQmvMrJC/MvYZX1Hx+f4auBk4pkL+2cBlqvqNiv7/Crge+GqF/JsxpfEtmvn5PY99hx8uKf8wMA/7cb2x5Nn+OnCGqp5e0baZwC3A8W1+d/4X++4d1+Zn/yHgAVX9QbF9pbSzrbXTF7BUpOww4DVV5wDvAN4Vqb8bsGqk/Bhgu0j5BxLy9wDeEClfDXs496kor2xb7pwxwNtavXeZ/JrnrDOU8iNlb0nUPRJ4c6R889Tnn5Cf+vwPT8hfDZgQKT8MeE277R/qV83nbyR/fl8Ddq0oW6rG9aPPdqJtybqdyG/11XM/92BbWoec/V9V72mh/gqFusMi7IGI/FpV/6uibBRwnaruFKl/u6q+taJsCWCWqr6lA/l3q+pW7ciPISKfiZWr6mmtylyc8ltsy6bAOAY+fz+rWXcUNhAp1j8td06lfBFZCTiwpPzIuvIT7VsGG+gU659Up36v5Vdcc5XEKQcnym9OlC9IlL+jk/qt6EXo8YKqiHwZu6GPYlM5wt93ish4zMQyjoEf/qRQ91DgJGwalq+7fiifgJkg1gv1xarrpqE8JX934Msl9VeoIx+4XkQ+C1wG/DMn/y+q+rKI/EtEVlTVv1bcnutF5APAz7TwC6xm07xfRNZV1ceLFWvKv0NEtlbVGSX1K+WLyN/pv99lfCv83RCbwWShKt4H3CoiDyTq3xwpA3gmIf8XCfkLYsJzyjH1/JwHbIoFzcsWuxTIlG/0+cLsty9g5ouyxbiofMyGe0dV/Rry34/lXVgt9G3A842ZGP6KmTb+XVJ/O+AEBt+f7Ps3Bvh4Sf8/UlP+G4HP5eRn9d8Zkw/8o+ReZByEPT8CrAs8G/5fCXgcM5lAxbMV/oKZeSZg5lHBPqc7gbWxz6hK/s2h/mqYee9X4XjHULZyQv72kb4NoqcjdxGZC2yiFie+WHY/FtZgwMOpqreE8keAt2ohrHBB9udK6v++pvx52MLJA0XlWlP+YyXNyj/8lwPbYrbdvPLPlMvfgWWx9YMXGPzj8ivsAbyrUH9STflzMDvk70N5UXml5J8EPAVcGOruDyyvqqeG8uuBD6jq38Px8sBPgEODqMPC3wvD3/2xtYzfh+PtsOQwl4XjvYG7VfXTCflfD+e/H1vcuigc74cp9izMdEp+6vOdo6rFpDV91Hi+ZuUGAmX1U/LvUdUtI+Up+fOA96nqgxXlv4vN3ETkIeDTmHLu8wZR1WdC+W2YDblYfkVN+fcD3yupf3dMPrBc+Fv5+YrI94CpqjotyNoV2ElV/ycclz5bqrpLOL4UW9N4IBy/Bfisqh4cjlPyrwY+rqp/DMdrYrb+99eRX5vFZf8pewFXAKtVlN2ZqPtL4LWR8t8k6qfkTweWaFd+jb4fVPZqof4OZa+68rER0aBXC/IH3b/8e9ii6zK542WAh3LHvy2p/9vc/9PJ2Scxe+n0FuTfWiL/1hbkp56fHwAbd/B8nQK8uwP5n8ZGrmti3h2rAKu0IH/Q/S+Un4MNvNrt330dyr+7Q/mVn2+ZbHJhdWs8W4OunX+vhvzfFcqWyL+Xkl/31Ws/968D94ol++ibmqmNDk8XkeOxlf98WWZ3+jxwm4jcWSg/Mvx7vIici7k/5cuzaW1K/tHAtODZky/PbJYp+dkv7sbYNCsrvyD8zTJXVRLWIzYo1L81/L0lVjclX/tHoKvl5efKo/KBl0Vkfywzl2Ij4/wI6kLgLhH5eSj/b/qzdQEsKyLbq+pvQjvehs1UMtbCXPqyNZTlwnt15Y8RkfVVdX6QPx5bqK4rP/X5ng/cLiJPhfKiWS71fN0B/Dysb/wnV3+FmvJfBL6BmY4GmSVryJ8pIpdhXill/dseODjMQMuuP11EvoGZicr6d7WIvFfD6LWElPxfiMgngZ8X5GefV0p+7PP9s4gci83qFPPOeyZXt+zZuiBX/mB4NvL18zOglPybReQ6zKVUMdfH6S3Ir0WvzTKzMdeuQVNXEfk65vrzaK5Mtd/mdhfmElmse34ovwh4EwWbpQabXw3512P2u6L8E2vKPx5bQNkYs4/uio0G9wrlG2A/bkXln5ltPoa5pY0F7sNMLLfn2rct8B1gI8wndhTwT+0326TkT8Ls42th7mLrAQ+q6ptryh+HuXNuhz2AvwU+paoLsmuJyJaYrzHYqPneXNlWmDvdiqH+X4GPZMpBRD6M2XSzh34HzEXv/JyMmPxdsNHh/PDWOHIuqin5NT7fecBnqDbbpJ6v+ZhbbZXZLyW/NNtZrn5K/g9LquX7t16Z3Nz1p5cX9/UvMyv+m5IflxryU2bNlPyyz/dEVf2R2MLq8cDbQ9mtoazPGSPxbI0GPlGof5aqvhDK68jP9rlk8n9eV35tWh3qd/MF3BIpewhYOlJ+W0L2A4nylPxUdpSU/Aew6db94Xh14Be58t8A7wJmYYr1hPAA5OuPJkzHMEVzWb59wBuwzRajMB/er7Ug/37MX/necLwjcE4L8sck+n86Fe6coXxU+LsCsGLFOWtgrqd7AGu0Ij+cswy2aWYzctPsmvJTn++vOny+riNu9kvJn0rcLBmVX+cVPve1sMXBdYF1O5HXA/mVn2+NuitjC5lbZq9uti1cYwVKTGrdevXaLHN3GOFMZfDU7n5slfnpirrTxXKy/oLyadsdIrKxqs6pqJ+Sf6OIvFtLNiPVlP+8mtfJS2Lumk/TP2UG84W+SUREbbRygoj8GvvFB9u2/IKIICLLqOpDIrJh/gKqOk9ERqltb/5hWGSqK/8/qvqMiCwhIkuo7ao8pQX5t4XR1WXYhpwBmy6Ae4Bjxbwefo79MM3MlT8mIr8M9X9VqIuITMWmrVNV9Z/F8pT8sCB3KXC5qj7ahvzU5/uQiFzM4OcvM2uknq8/YtPzayk3+6XkvwzcF0bQZWbJqHxJeLOIyBHYs/InBnrrZAvuSVdGEVmbwd4ut9aRH855W4n8C3LllfIDqwWZSwJvExFU9WdinlBfKJGd9a3Siy+U1/Gki8nPe/q9ktWn39MvKr8uvVbuW4S/2+bey27i6tgDPoPB9niw7fdgtvd83UyBbg8cFLHppeQfBhwtIi9i075Q3HeDU/Jnivkifx9b0f8H5nmS8UKwhz4ilgzlD9jDmLEw1L8SuEFEnmVgesN/iWXGuk9ETsW+zHmbdUr+cyKyHDbl+7GIPI155tSSr6obiMhEzF74RTHvm0tV9aJQfj5wfpiifgA4Rcy1coMgYkPMteww4AdiHgSXarDBYyajfYGTgwnuMuBqDVPTGvInhfqXi8grof7l2u/aGZVP+vN9TXj/3bl7pvS7Kqaer8fCa+nwKpKSf2V4VZGSfxXmbXIjA9dKMo4CNtTg/VJRP+bKeAp2f+fk5Cv2vCXli8iF2Jb/+wr1L6gjX+KupD+mxBMqxz7A67XEiy/wv0Q86WrI/yy20asqKXZKfj26PRXo1ouEt0aN+uuVvRaX/MK544BNC+9tjS3yjAV+iD1020buxSRy0/xwvddgU7vjsXAAb6grH1PUo7Af+IOwnYWvqyu/0L5VsS/dyyVlEzFF+ig5s1ThnJUj9UcBOwOXA39rU/4GdeUD42OfLxYWAmDvimstE3u+gAtD+VEV9VPyb8qfV1IelZ87r463yZKR8t8l6s+lxBTWgvwHCWuCbcqfEylLeUJVevHl2t62Jx1pT7+o/LqvXi+orsjAhYdbsJgnfw3lq2NKCuAuVX06V3cpBi463Aycrar/yZ2zGf2LFr9W1fsL16+UH8on5eWr6tWF8kHyw0JMJZrYZSaJXXQ6fHbgroB5EUzGRlg/x0bGmR/yKdjo41FMcf5MB8fL2AEbfe2KxeS4TIMfdCh/DTa63xeze16tqke0IH8cNgrbFxvdXaaq34rJx+z4W4nITar6rpJ+PxDOvVNL/Mwl+J+LyIWq+qGS8jmhv1OxBXcpnHJLQv4c7Ln/HjZ7Lda/KCZf+wNrfQVbtyr1NhGRH2Czq2soN+ucA3xHgy92Sf1rsR+o0k1FNeT/BDhSgy94m/K/pSVmNRF5F+bdVeoJFcwqV2HBxgbNukRka8xsUupJV0P+FtiAq9TTLyW/Lr02y5yH3cB9wvGHsE6/X0T2wVy9bsYe0O+IyOdU9afh3LMw39Uzc3XPAj4GICJHYTbFbBp7kYico6rfCeVR+SJyMqb4fxzqHyXmujclJh9TOFWoiPyTfjteGZuE8uKXtm793yfKd6woz+x+0frab5a4HzMLnKSqt5ec+hjxTWaPYVPuy4HPacHuLeamtw02yjkD+3HNT3FT8u/Eno/LMSUwv1BeKl9E7hXzdHqjlIc6+CXwZ8yV8295kdh9e1xEDsJsvGXPwveCjPUxk0b+c1Zs1BiT/xEsquJYbDZFoX5Kfma2PAr4goiUeptgOyofp9qsk3Jl/Bdm0isquGxNICV/VWBOMJmVmbVS8mOupB/GHBSWonz37/nYPoEqs8pXMTPr6Iq2p+Sfja0ztSu/Fr0eud+nqpuXvRcWxHbORtNhAehGVd0sHN+f/Z+re3+ufBb25f9nOF4WcyXMFjVS8mcBm2t/ZLdRmGfJpnXkR/q8Q6xcE/7lUuFClmPcUMrXflc10fDwBNv+cqrap4zEtqffp6r/FJEDsNHo6bn6K+TPL2nHLsANWhFHvob8N6nqQ63KF1u03hP4FKYoi/3PXGGvUtU9SuRuj+1IqE/AAAAgAElEQVS23Yf+7eu56n0Llmep6ici7SuVnyv/kqp+OVJeKl9EtlPV34rIaC1xrctmHCJylJZHRxyvqo9VPSe5+39QRdN2SshfRlX/XfU90f4dvqXytd+VtdKVVEQeUNVNKtqHiNyiqpXfUxGZqaoTIuUp+bep6tvalV+bTmw6nb6A24Htc8fbYQoSCq5omFvhA7nje7BFj+x4feCe3PEDwOjc8ehC/ZT8WQzc8bcKFkyrrvwDy14t3Ju3l726eO/XLXu1UP9izB6/LOb290dsBJ6/f4K5Ic7CRoq35MpPDfWXwqavfwYOyJXvjYUzADgWG/Vs2YL8o4J8wXZ73kNux2YN+aWRBVu4Px/t1fcq0a67s+9PRfkcbG3hfmwtZJXCK6t/U0X91JpASv494bwL25GfO6/SlRRzcojt/j0N2yPyVkpcIYGTie/+Tcn/KnAI1buLo/LrvnptlvkE5vGwIvYl/Av9kdl+Kf27uMDsonn74Ocwd8j5oe562HQo44fAnWK7zMBGY/k4yCn52e7Z6UH+2xnomZOSv3Xu/9GYz/k99K/2P0aJ+UPDJo3Qv3z9idg0O79JJKu/NKYk85uMUvKvKcgfjy1SZZuYovKxh/dvYrtUp2GhWO/GTF0AL6mqisge2Ij6B4XR1rtV9WgR+W8sAcbe2EJSFgvmS6r6kzASfg/wTczstk1N+R9R1dNF5D3YztQPY5/Z9XXkq+q1xXvXClo35vbi5z9iG5jGisj/lZSnzDp/TZit1gyj7kliMVKK5sWU/H8lzFpR+dq/phVzJU15QsW8+KDfk67KpJWSn/L0S8mvRU+Vu6reB2wmtjiH5qbpqvo5saiI22GdO0dzu7jUfLg3wBZlBIv9MGDxQURuxm60AB/W3C6zGvIvCfW3DuXHqOpTLcg/It/X8AN2Ye6t/LRrNKbc+hZTVfV9uXJEZB1stJuVL18o3xP7Aagrf8C0UWwh+NBceUr+UmKL2nsC31XV/4hI/sfk7yLyeWzr9NuDWWupfP3w973AJWoZkPKXzMwlu2G7864SkRNakJ8Jey/wQ7XF7vwFUvKbyu5YJqB3Ysp1AGpmjf+LmHUys9WS2Pb+IscRWRNQ28Eak5+ZtVaiPwpjX/2UfPoVcMyVdJeSdmfXXwJ7Hi6vKBfMjXFQNNYcKfkHqOpvO5Bfi15lYmo7JnfFr3memxOyo94mkvB2IR0ytlR+UISzVHWjyLV/o6qlYT3Dhz6rqJQL59yhqttGyivlh/JUpME++SJyJDZavx9TkOsCF2mIYS8ia2AjlBmq+msRWRd4h4ZNKGIL1ntiGzkmYl/mq1V1m1B+NeabvxOwVTjvLu1fE0nJ/yEWgnU8ZroZhS2ablVHfpMJP4RHVX3PJJ0vYAlgX1W9pKJcsJlRaWz2mvI/r6pfbVP+KMzT5tutXjucc6uqvj1S3lEuBInkakjJb4VeKffjw79lcZPHYSFuq8hc5bKYyDdho7QdMcW+Bf3eJmUxlVcl7k2SjWbaitmsquNDH/NxxUdhMVou135vm7wSXSJc6xM55fWdXP0lsAwyC1T1gFD+/pL6O2QPTQ35nymUb4n5ub+njvwi4Qs3SlVfKiuvqLMy5rv+stiC9PLZ7EhEXouNgB5Q1UfEwqJuotU7houys3s2X1WfE5HXAWur6qx25Iu5x/1RVf9QUX4+5sFxhqr+rqR8TeAv+dllofxGbAp+hhZcbmvKzwJLnaGq303JF5HpqrpjWVvC+T/GFGzpCLITBVhTfkcKMNa/Gtf+EvZjPygXQyg/A/iRluRCqCn/RGydaFCuhjry69Jrb5nKuMmSjheeiomciqmckt9pzOb8avtLwO9VdWGu79ML5QuAb6rq3FB+ULE8P5WTgYGfsvrf137vn5T840vKr9D+4EdR+a82gnLdFHhYVfctKd8a+7HfRlWPLim/EdsPcIWqfrakfC1sgW1bVT2jVfnhnNeF+teUlA2QLyJfxYK2FRVYFrgtFc+/UwWYkt+RAoz1r8a1HysRqdoftKzTXAipXA1R+XXptXJ/CNgsG82Ixau4X1XfJCJ3ZlP03Pl970kh2H9xOlT2yy45F6Ma8ivdNOvID8drYCYHxcwHT9ECYtv/3xTqz9Xq7dBtI7beodkPrBNHRJZv916F2c3Gqjq7g+unUsUBvKKDY/0U5UwveVu1P6pjyhWxUwWYkt+RAoz1L3XtFJJ2Ax1S+XXptbdMLG5yKl74zRKPiZyKqZyS31HMZrGQvcdhmxWyTVInacgqH0ZZx2MLsopFcTxJ+zPZvBfb7PBoqD9eRA7V4MUhIutjkRG3DfVvBz6t/fHLU/InYN4jy4fjLOTu3XXkN50wWNgMi1r4PDBbVf8E/FYGLvwWGQ08B/y/ivJbQ/2yzSvQr9DmVpS/BVsorBoorBfaH0s395SqvjFSnlREGsyPEXbtUH7ZYm0r8itNTnWVbKR+VMkOtfy6DIcE2VvRnxuwL26y2NbxVLzwWEzkaEzllHzpMGazWJq2t+WU6euw7d4bhuMbQp3M9W9/bEFwp1D+ELC7qs4Lx68HrlHVN4XjO7Cdldmi1mTgiNzMIyV/FnCYqv46HG8PnJkb+UTlF5EhtkmnSMlvQc7rsYXinYBHgEWYwn5jkL8O/c9MGdmovMpeOgF4RlXHVVx/dpC9W0X9aViMnNIpuojcC6CqW5SVZ+fEyp2GoL3fVDGkMZ172K+bGBjoa2lsB2x2nErFdWuhTBiYJq4szd0dLchPpbmLyi8pOx+L/X5ZRfnWWPTGUyvKb8RCCnwzUn4t9oPXjvwHw+vwhPxbsB/sQUGrsEX804mkQ8RmattHytcnvsFme2D9SPnohPyNyG2uq2pDO8+0v0bWq9c293xM55fJ2c0kHW86mr1dLM73Z0vqR7On5+QXs7tn5ZlNMSX/AixOzFXYSGwPbIHl4XDqWlhCjMyfdi/Mv/X4UP+scO3LQ/29sal6tqg6EZv+Z2alfbHkFNli3BcS8r8NvJZ+s9a+mOdP5o20T0y+Vrt8DolNOrXgWFN+7QXHmvJWwZ65Z9toy+r0e149qWbyqSU/3KeJ+fqYG6dKInCZ0zqdzip7Ra+V+zxs9X9QTGdJZ09PZW9vK3t6Tn4qu3tKft4bpYzPYvbVzPa6BP0r60q/ki1DMdfPWPmYhPxBG1gK9WM2VcWyNA2ySQdzT4yUTRoskUhVtMGU/FFYKIP/jpwTXXAUkTdhP8Z55TlVVR8U86c/Fdtx/Bw2qFgBG7FPUdUFYhvWdinUv07NJXNz7LlZEfOzB9uQ8xzwydD2SvmYeehMzGSUr/+GUP80bJfwcQzc5Qz07dAs63MjzGoR+ZX9q9G3lKfTYnVjjfc0V6/Hyn06FrxrkG90mbdKofy3qrpdpDzlB5uSP8ibphX5ufOWx0ZfsQWuEcNisEn/F/ZDVHW/lsU8JKp+3LKZ0ZMV5ZknQpX8LArfCVhYBDDlORmbxeyBJVP4qYagY2KbZvbGgo2dic1Gr2eg8t0ZOBELZnWoqt6Zv6hYztqzsXsYk78iFvdmQaH+eMwe/3FqBC4rIkPv6plSgCn5HSnAWP9S1w7ntD2rrCm/q7NK6L1yr4zpLOl406djORJLs7eLbSV/mors6TXkn4yNAn9WqJ/5AafkvwXzBspc1/6MBQ7rezgkEi9eRMZiCaozRfkbbFfhwlBeJ559TH4qln6pfMyb6Swsfv2Ah0dEVgO+iAV/Op8SxHyAj9P+jEvF8nuBZzPzVkn59lgc8dIFwVD/iIR8IvUfxmLobFF4f2nCD5P2Z3sq1n0EmyltU5wZiG3YuhP7zlXVn2fio/IBNioOiEL75qjqG8LxR7WN+DZNN6vF+ifp3ekQmVWmkC65sda+Xo+Ve6npQlVPlHR28x+WV+2zmaf8cFPyU37AKfm3AV9U1enh+B1Ygum3heNivPj9sEXQbAfrDVjkxSwezQHA/qq6cyg/F4ulkinRD2FeFB+rKf8KLJZ+vv5m2r8JLCq/Du3YpEVkfU24W2bnlMmXilC2ufKNgMeqzgnmuI8VfxzEfI+vxxaN/4LdlydC8TpYNqtVsV2xW2c/krn6K2JrINdiI9wLCvUPxBaUV03IvxcblV9aKJ+M7YD+eu6alTlIpcLVswlmtXCdQf0Dbkhc+81Y6sD7K8rrzCo7dmONyIcabqwZPXeFbCpSL958LF58ahNVz+QPpU06d63SBcea8ttecBSL8/5dzOSUKc91MZv24eE6H831X8J5v8Cigk7G7N3XF+rvDHxZVX8ktps5X39huH/Twgi8Ur5arPONKur3ZR2S6hykp9Nss5pg/f0Lg/v3Buyz+Snl/bsEy0sQczONzSqHlRtrTzcxiXmsHI39Yo7O3s+NjlfG8l/my7IEuKOxL0Gxbp9NMZhGNi6U57OnV8oP5buVyM9nd4/Jny+2RTs/8i6O9lfCHkIwW2qeP4slocj8zPdj8Cas16vqo6Et6zM40XFM/vNimaV+E+pvh41wovJF5JjQlkvpT/g9FrhELGRDZpPeXwfbjC8VkTKb9I7A16R/y/mgBUcRyRYcz0jIP46KBUcR+SSwtERCyqrqz8Q8obIfh0x5ztD+xB5nhVcZ54vIVCyMcFb/ZizWyLPhGtdiI/hBqO1CjslHzYmg1JEgxwTMRFI0nV0SZB8aMavtEDGr3UV3zGqlG3XEdp52Yla7BAsEt2FJ/3bHFHxV/94W2lfFBxKzykOxgUhV37ZiYLTWIh9ksI4Y1IZEeT/aQz9M7Av+UexB3QFLu5clCP4YlhDjWWzn6fPk/IOBn2B5Bh/FpqzXY3G9s/LjQ70/YTsxn8IWqagp/3v0T52PD+f+oAX5KwP/h8VwvxcbMa2cK98PG8H8CJuCPwZMzpWviy2ILQqvKxmY4PtdWCC0mzF7+QJgxxbkb45NPxeE8+4ll8S7Sj42slqq5LNcGlOoj0Q+70ewKetKJWUrB9n3YTbrYvm2ob0p+Q8C40rKxoey7THl9kz43PKv8zp8nkt98Fuof0gn8oETCt+PNTtszyr5Z7ZmnaQPfXZOmXzSPvpd8eOv6hs2qNgXW/j+dPh/pcI5q2OB9rYAVm9RvmA5A96PmZ62od+CEk1U0vLn1w0hHTw8WVaXfIajW8LfB7AR8X3h+E3kNshgJoa+uph9OK+cH8Cmh/fnPpBfFMpj8mcV/i4HXF9XfuFhWb6i/2sCk8JrjTbu3zKYB8BmlGSCryMfM2msUFc+lnVpvZJz18MU96XYyHkbzN65Vvj/TMzn/mFgxYr7lPpxmFdD/iPAkiV1lwbm5Y5bzpSEhSSOlZ+YKD8nUX5oh/Lfl/t/OjZwuQ4bJEzFTDfZs34MNvjIzDQbhbJ1wz1eFO7lPMxx4FLCjyYdKMCa8jtSgFX9S10bW/d4FPvxPza8vhfeOxAbEN2BDRJuDK+Hwntb1pD/7vDetcC54fXL8N67sTWwg8L13l98tfq89jq2TObZ8cdgAnkSm0IDvKCqL4gIYnkVHxJLFFCs+1wwjzzFwPyhz6slPH5JLDjW0/RnOqkjP1tw+1dYiX8GBvh+R+WLuT+dR0XslsBb6Y/9MgrzvMnqp2LHjMbMFFn9X4vI93TgQmFM/oDYMyJSjD1TKh9zx7tJzHMjZpM+kWqb9D1iEUEH2aSBLUXkGsoXHH+JKZSY/M8AM4KJqLjg2Oc9opa5qXLBsYKPR8rQsEEswtmJ+qnyqHxV/UXu8ISyc5puVsPMrKX9w2aHR1ddO5RvpdWeTv+i2o31h/S7sVbJXxGLHLugUL/oxlqVqKR0j0IVvfaW2R3bSLQO5va3AjY6mSoWTOzDmDJ5JzYKWUpV3xvqfgzb6LMJZnpYDgvgf3YoPxPbpTkZ+B9sAeY+Vf1wKE/J/1Jo07uwB1KxkLfH1ZSfit1yJqYQ82n+HlXVw0J5KnbM5cDf6Y8dsx82Ddy7pvxU7JlK+WKeCDGbdJTwZcnbpBdiC6rPhvLKBcea8ttecFTVI3PnVO0QrVxQrtm+92CJSvL1r1LVX6bki8iS2I/bf2Ozlr76mNnwP0QQc/V8c/E86Z6rZ0wBng28NiH/JTrw48cGI1X9+4eqLk0J4dpK3NMpdm967sY66Jq9Uu4SyZZScu4O2K/eL1X1xaBc9tJ4KqyxqvpEOB6HmR5K3bAq5G+rqreF8mUwO99f68qXkk1W+ffEVtbfotk81K75gKpmOUzLQhLnMyGlvGVS8lMhkaPy20FEdtcWdtgNpXyxTTFlC45RbxzsRzIbGZZtcjoLy425J7ZLGGxWdxWW+PgEzHPjgkL9A7HR6pMJ+ZuFdp1fKD8Is/Ourarby8AcuIR+ZD8E79HCop90z9UzpQBnJuRvQQcKUMyVtap/D2CDlaprX0PE0wkzvfTcjbUuPTPLqGXfmQQkU2FpIYRmMIccTn/clKJsFZErsVVzSkYBdeR/CzNroLalOr9RKSo/cJeInM3A2C03S/9GibnYg5M9hOtgU9qM6SIyhYGxXa6R/o0Q94rItqp6R+jTNvTHnakrfzIDY8/kN4ek5A9CRK5W1d0jp2wNVCpfETlHVQ+JlB+iqud0IP8EVT0hHP4O2wT3x8JplxGfWq9C+cjwNGzkuyP2Q/AO7c8qtQb2Bf8Jtl4xyE9ZRC7D1iM0If8VDZFFcywE7hCRhzPZWhEyV8zVs7FmNeJmww8GWaXXVnMzjXk6/ahiVnmGDnRjjcm/MtR/a67+/nVmlfSHQ69Fr80ysWwpIzoVlpRvguprJmYDz7K1EP6/HZvWgpmbYvX/je3uzdq/LrbQ80oofzYhf0fM5zh7eEYxMPbMH2LytcRXV0TW1JAZqx1EZCsduCZRLD9UE3bphPz3abBLh89nc+z+5OOhbJSYWr9MfORLifLNzpkbrvUxVb2rUDYRU15LJeQ/C3wL2+af7WFYAvvx+UxxtlfRjkab1TrtX6+pmlW2LKfHyr1MAapatpRGp8KSimwtuXbcEiuXimwtOcYNpXxV/b0MkU06RTfkR+7/J4hPrc8jvsnpM5gXxfnav/FqdeBgbHR7NGa6WZ5+s8o6wN+wBccxCfkPYdFQs3UiwQZI07FNXGXfi64wEsxqQ3XtTmeVNeT3zSpF5CeYybrtgRL0eBOTRrKlYFObWN1Y1EJIZGqpIb+jTDApUsq1Rv3SjRI5UuVtyc9s0iLSZ5MW8xYqs0mXeWNEbdJqkRMrFxwl7e3xTWosOFbdfxG5nfTUunKTk4jcGe7DLWKbgsD2QkwF9gkzy22CqaavvuZSMMbkh1P2Dee9Dhug/bmsL63SELNaJYn+Ra9NwtMJ+5xipOTnZ6yrAnPENozlzcGTEtcY2KBejtydkUdQfrGohVU26cwbYz72Q3B+iU16p3BObMFx14T8mXSw4JjNzNq8N8tpjeifob+o6lNiu7T/C3gob3YonP9JVT2zomw8tgg5R1UfarftQdaIN6vFFGCn/VtcVM0qWx0QunJ3WkJEHhlim7RULDgKtuDYifyHy2R3CxF5XFXXDWajtbHMVf/Mle+Cbfaagv2YnIKZa2Zj8VxOZXCYCDCX26+F/9+uqnsGeZlP+s2h/tdU9UcVbRsUEreJZrW8AizrX+zaYh4/bc8qa8jvyI21VXq9ielVgySSIdSoP1yywdwt5kNfZpO+F7NJx7wxPiMiR1Nuk34CWE1EJhYXHLFp7QtYAoqY/BNEZG/KFxxbzphUREQ+U1UELCciRwKHYYvPPxCRo1T1qnDO17AF0zcDr8FMZ28II/iVMbv56zF/7tn0T/VHETbD0R84C2zn5TtV9TERWRVL7fijivYdiO1Y3lUsZlFTzWqDXFlz/VuABayrunbU00nMvbhsVnlkWETOu7GWyc/cWE9g8KzyIhHp6qxyWI3cO1GAw0j5lSLpZAjnMzKywZyNKYlY1MJKb4WgxKaE+kWb9CnYQnDlgqOq3p2QP44hXHAUkRewTEeDEsxgW/GfAN6qqv8IbfkptlX+dLGgV6qqWwZZA/YNhPI9sGxKj2Ib+v4lIvO131Hgnlz9u1R1Yr6+5gJqVYxcG21WCzKq+vdDbD9K1bXL3Eyzc+rMKqvcWOvI7/6sUluMVzCULyJJlkPZWdjGnLK6nSZYTsmvm2A5FdypKs5MNMGz9sfceHNF2VqY3/1hHch/HbBbO/Jrfr7LtXDuGuF6E0jE3cGUflV/Vu3Ss7kHFuPkNmyLetk5T2C27wF9xvy7T8Pc9mYSAq9hG+Gy80YT4hTlrvdbbP/B/Nz7L2M/dH8HXszuDRY7Zxbp+CapwGup2EFzI/XnYoOXqme3U/mlsot9iJS9mLj29Zg3Uz4WzurYDOnGcH8nltSfiG2QSvXtDuxHZolc2RLYbGlQQvpOX8Nq5J4hJdlSZISlwpKKZAixfgc5jcoGU7h20iatNnWvXHCsMIv02aRV9bTCNbuy4CgiX8P2HqyIBXEa5KESzEuXYP7m9+XeXxIzV+0PjMfCwhZ3YK6N+djfmHvvtZjXzjaq+nYiiMhKWHCs04iPzBcwtK6eqxH34/9cQv4JdODHH8wfVf17C/Z9rLp25unU1qySYebG2ms/95YV4HBXfpLOMbo2cdvviM4Gk7BJfxH78mY26c2x1IFXhbr3YGaf2ILj/zLYJv2p8D7AFtqlBcd2EEuP+JLmXBtzZdupanSXb6dIesH7zaSTgYxYs5okkp1gn3FHG5wk7sZaawOVdNmNtbSdvVDuCQX4euyXt0oBDnfl95pQd10t3Fwxv+f7MZvtFRX1R3Q2mC7YpJfEzB9VC46TiNuk+9omlupwf80tOGpFbJz8zAtbmBwyb5GhJDFyXVVV9+lAdi1Xz3BupQIsObfU1XNxKMDctZYLz2Tbs8oKuYvFjbWMXnnLfIXqbDAPYSEF/kq5AsyUX+kGqBaUXzGkZka3lN+gX01VfVpE9taKLDOBEZkNJoySn8KSk1ypJf7OYpE8R2UKQi0l3juAn4q5Mgo26/oXFmr50UwpqOqzIqJq4SL2Cte7QUSKsYny933JbKSnqn8WkVcK7elbcFTVJ4EnRWQnzD5d6vGgqicn7k2vOZB47JZOmAO0Yla7O1OAIhI1q4mFmB5gVlPVZ0RkvIi8nSFSgPm+icg3iXg6hWd0inVV8rPKr4tIpRtr1jeq3VhPFpGuzyqHnc1dcqnf2jlHEgmWg+J8suqc8EFMiMiPJlgO5+yELQZGR35S7Wfcdo7RmvKFNnOMRvrcLZv0vdjI/j8iMlZVF4ZzRmOLTnnvkkE2aRF5mf5wEMtgM6inwnR9JrA78aiP1xPxeKgyeTSFJpvVavTtD3Q2qyxzY833bc9OZ5Vasl5YRS9D/iY3MoxE5ScD/XjLQrZeTFy5vJ3ByRDGYotVWTCzQckQgqxPYpnjY/LfSEUyhFD/NMyschy2+DUAVW0pYUCRlE0aG2XWWnBs8bp1FxxXIrJJSqtd2T6JJXS5otj2mu1Luap+DZvNnqshoUor9cM5ydgtTTCrVSnAGn17UlU3zp2/XOjfHGwN4BXtoRtry2iX3W/qvDB7+32YsjkgvKaE977OCE6FRTrH6O2Y69OoXNkoTPnfQec5RlPyO84xSiRN23B/kXYF3CX3+Z8TXtnnv0uk7mFYcpepFeUpV9zMVfWUivI9saQwF7RTP5xTmaaP7rl63pMru79w7r2F65W5eubr31VVPxzXzvEarjcr0bdfAZsX3l8S89l/mR67sbb8rA/Vlyhxo2MK8HlGsPIj7euaUi6d5hhNyX+EDnKMEv9hntKL56nFZy+agzWcs0R4Xj4QvqDb5p+XNq/b8T6BIb4vX8Ps8rdSsTcA8/nuigIM770WG0nfmntvSBRg6N+vgBsjfRtLda7h7cK1y747a2Pp86J9i7RtJSy+e1Q3tfqZ9spbJpYt5REdwamwxOKHxHxdDybuZzyss8FgM6URa5OWhKuc1tjhLIn4IrnzynaIRuOXYF5YldvvMaWR2v4/ZLFhhrtZTUOmspGIJNxYW/1u9Uq5xxTgQszGNSKVn6peIHE/3qRykQ6SIdSU33YyBMw0tdht0ilSNukuXeNqbKQY217/LeJrHmdTvn3/4FDnz8S336+UqH8jkTUfVT15KJX/UFNHAY7U/kmX3Vh7uaBaqgCxaciIVX6aS7A8kpHqHKPRmUlx9Jqrdxhmq19PS8Kyprwdaiw47ol9Hpup6oGt1g/npBIqrAncovH4In8mvmC7cuQHcC7Eo1pacTz+CfH4JueSUP5V/R8OpBQgFhd9RPavG7PKAbRqx/FXny3sQcKPYwt1rk6Up+LSnJMoP6RD+Sfk/v8JsGbFeYvdJk2NBcOE/JYXHClZsCMdXyS15pGKXxKNP1KjfmrNJ7rg38lnuDheoZ2fwBZxH8AcHK7FPL2WGen96+q96nUDSj6ESgU4UpRfpH70/KJyKSkvXenPlR/aofz35f6fju0Svg7bWj6VCk+QEjnvwRadp2K24LMo8TQpU541ZC+JbdT6ZVC094cv9/8r+1K38fylvKm2DEp2TlC012M/9HdiP07RBVts4f+UoIT/El4PhvdWCde4LFz/4fB6Orw3vkb9qLcPCeUfuS+fxH5gBi0oduOFLXgeA7yuQzkt9y/VNzoPOhjtW6p+OCeqm8pew3ETU2W2FBE5UVWPj9TtKBNMDfktZYLpiq9qj5A2ssF0ySb9LPEFx7OI26QPidXXxIKjJELialiwk4rt9d2cWkub2+8Taz6NNqthPuwt9a9G3+oGHZyoqse00bdo/XBOVDeV1um1ch+pCrBK+WGLtpXKS23LfSOzwXTJJv1X4guG62rcJv1Yon50wRFzAe2ax0IriMiWqnpPpHwNjcdoKa0vIquo5W7NjmsFt2qx7R0pwBryayvAbvRvpOqlPL3ylhmULYWBo7fRjFDllxr5AT8nrlyybDDtJkN4MiE/ywbTVjIEzWWDqXD1m0U85OvomE2aU+cAACAASURBVPIknTDhWSIhYbE9EJ0sON5Nmx4LktuBWFGeWrD9vqp+PFJ+japWBYRDRL4P/F5VvxKONwauxLI/CbCvqt5ZVT8np21XzxqyF2uquZLrx7JEpfRSalY5rNxYe6XcYwrwVOzLNSKVH/CnhPJS2s/W0vNsMDW+AKsQj3n9OeLeDisRjxf+MQaGhCXUmU6/q2Gs/ljiOVg3oZseCwOv0fLUuo1r5Le4XwN8V1WvDT+u/6uqb4vUHfFmtcS9mY/Z5Kv6NpHOZpVD7sYa69+g/vZIucd8VV8Elh3Byi/lqrUpceXyezpLhrBUQn505KvpZAhDapPGRjeV8cIL5oVBNmlJxxufSBs255L7kIxdFKkbjY0UntXS2Eap+gXlXoxXUhmqOZSPeLNaTAGKRRl9faRvdDirJNE37WRW2apJsFfKPaYADwA2GcHKL6W8diS+g3VYZ4NJ/DAPqU06RcomnTsvtuB4LHBm/kekUPfjWIwXpSRwm6rekzD7HUg8MNxTxAO7rZGo/39YCAHBXFTXUwuhjIj8TlXfkutL48xq+bYV+1ejb7PpbFa5XKJvf03Uj84qq+5LFb1S7jEF+ATwbUao8qvZ/24s+PQkG0xqZjLENunUgmPKJp1ccBQLM3s08AIWmz5LJLMB5h21OvAhVb2uIGNbzCR0MXGz34ex2EfPFeqvjD3bLwO7quqCQvl4LJzsEon6RZv93WoRHFfH9iT8gmab1XaO9O9CbHd7Vd8eoINZZbhOrG/PJep3ZVbZd096odxTjGTl1wkyArLBpGYmQ2mTlsSCYw35tRccRWQDLFjUmlgwuwexEfGsyMh1HvAKcbOfkoiNRCS2UZBfWT81c2q6WQ2b1UT7F9MN3aJd3dEN3dcnazgq9ypGgvLrBBF5HMhng2knGUJpNhhCAmmqs8FsRxdzjHZik64hO2qTTtRte8Ex1Pk/zGd5FHBSeDsfu2gn4iPLrxGPjbQmkdhGoa+x+m8DvqMlOYRFZFlgPmZe/HFJeRPMakNiNuzCrLIrbqytMNKU+4hXfjLys8GcABw0VDbpICO2YPhuIjZpVb0+Ub/tBcfcebtiHhd30K9csthFyU1Cko6NtDGW1KI0tlGsvohsjj3Pm2Bb8/NmpRUws89dWIjqJprV2jIb1uhbR7PKGn3rihvrAJnDTbk3QPlVbeLIcozewgjOBrMYbNJPEl8w/Dxxm/TXE/VrLzjGiCmDbk6ta7ZlkqpOLby3HJYrt8+spKpzm25Ww6K6Dkn/hppOZ5WD5A0n5R4Ux+XYCHtEKr9I37Ico9tjgf3LEkg/gY34Os4xmlPC3wZOzfWvoxyjmVKVobNJv0J8wVCI26RfTtSPLjiW/TAX5JyDZVw6v6jcg9ljX+DfFWaP5bDYMN/AFM+1wDeyeyEiV2Kzzm+H+3Ak8CXM5/thbPS5UUmzzsQWBNGaaRBF5ApVHZToPFfeSLNaqFfZt05mlXX6NtSzyjxLpk9ZrGyDKZ53qup2xUIR+RjwlIhsnim/8MXcHVN+mwD3ishS4QuzW67uaCzS3uPAXkH53SAi3y5cZjMR+RtB+WW2sqA8RknJJh4RGaT8iqjqF0I7NsTimpcxARuFDFBcQZEdKCJnY6MQDe8vzJ32OswcktW5SkRuwEarC3Pvj6q49muxgFyXYbOY/XXwgtSl2GgXVX0E+yEagIhcG750ZTbpX2I26bWwWVWeNTGFlm0GK5KVnQfMCNPvok36B5g3SmV9rYiNE77gdZIPn4kp3I1F5CcMNnucBwxS7IE5WGTGKzCTzkeBW8RiFj2DBbc6B1P+y2HP1DGhT7tj5p4dsPv4NP0zz2WB94V+R5W7BFdPYP2K8lKzmogMuVlNbO0ralYrNHctVb0WQFXvEpHXSMSVNZisLsa8ZeYW+4bN7rJZZeYuORa4JDxvZbPKHYGviUjUjVUsn0GZG2u+/voiMhX7XMeKyGuzWSWmF1piWI3coV/5ackqc/jFXYouZYIRkddiym8bVX17ol21M8GkHv7hjHRhQUo6sEljZp3KBUNV/ZFEbNIiclCsPukFx8qRd+HcQzEFUTR7pMyKj6vq5jk5B2CmpklYpFHJmQXnacj8FY7vwX6AT8Zmq99TVRWRx1R1fKy9ORnZjG4TzEzWKLMado+rzIZ7YWacI1V1UUnfXkNns8ohdWNNzSqL9DJZx4hUgCnlR8OTIWjNbDDSgU1aEguONa7dyYLjxZi/9vuo2P6euPYL2Mj7A9gsKM+nMYW1laq+kKuzE5bkfVlgkapuGt4f4MUlYU0g3L8jMHPNMdhzVToSj7RzdmhnI81qFWbDM/I/liV9e4m4p5PQQzfWVunVJqZjGKEKMKX8sNHPqzbHaKc2aVX9R0L+m4jYpMsGB9LaguN1RGIXqerOifbdhinec4s2UrE1ldOAe4rmIRHZAjP3/RT4cfE+iEjmbfOp3HtrYbPICW0o91IbrnTu6plSgOcRd/X8cKx+J9+fXN8uwEbx3y707Wo6mFUy9G6stWaVfXV6pNwfZoQqwJTyw5JHdG0L8UgjNzKehN2TMpv098p+JMRcXbcjvuC4Cv026ZOxketlmE36U5TbzWsvOIrIXFXdUEoWHLOyRP1sTeX6kh+31bWLC5N1EZHXaSGvrIi8W1Wvrzi/sWY16U/BORn4Tb5vobyjWWWsb6n6NWaVld+d0r72SLk/REMVYOrh1+pkCNEE0tJ5MoRoAulU/XBO1I+5cG67Num7GbjguBWWIeoZMW8nEjbpTRm84LgXNiJWVf1Iot3XY9vfP6Sqm4T3+ra/q+pONftfapaSdOya87DvwKUV5VcD15bZX4NyuxxTJmeLyIRw/Aq2VnVgccbQavtD2XA2q9VSgLH+VZyfnFW2QyuzypZl90i5t6wAR5LySz38FXVHRDYYzKwQDcla1ccgI2WTXqDxBcclYzZpbFrfyYJjtv39KOyLBeYFMWj7fEX9zCx1QYlZZllswfA92DNRtk9gPuZV8Y+K8vsxb483Uq7cxgDj1RK9TweOVtUZIvJG4GJVnVCz/SPSrFanb6r6QFG51+hbnVnlsHBj7TuvF8od0r/+JeePCOWnXYzXLcMwG8xisEn/jfiC4wkkbNLSnQXHlkZ2uXrZyHJbbAGwdGSJPUuD9gmo6vNBTuk+glx51ZrBQ1guzpdE5A4NsWJCnQey2UiN9o9Is1quLWVmtfyofw3gkkLf5gO3YYu6A6pSb1b590TfytxYa88qc/2ot5O6V8q9GwxH5RdDRK5W1d1lBGeDidmdu2GTBj5IZMEx9eNRqNPWgmP4fC4CbieSiaik3rWqumv4v6OptYh8R1WPaLVcRI7APH1GY8/MSpjv+7uA9VX1QzWvPyLNajlZlQowfDbHYrOgfN+yWWXVBsrUrHJI3VjzsuoMPIadcg82xe8wQpVfom9rYr/msUw3wzobDLYLuDIkq3Zok65RL2Wzfifw2jLTXERm34KjiPwv9vnci408YeDnc36VGOBqVV2z5jVTO0RTsU5iNvEdMYW+ANuouBDz7z6PGs93ot3D3ayWpeH8FLYhsnb/crPKL5SM+uvMKheXG2u9746qDqsXtkNvGqZMtg+vyeG907HR1L7AqFydUeGcO4Drwk1bI1e+Bqb4b8CmYmdh0+ax4bVteO+yGvWPAe4LxweE15TsvUJfVgFWLrz3cEW/BVMej0TuzSPA3Ej53ET5wzXqPwwsVVK2dLj+ylhAtoewH9JnMZPBKcAqNT/fTYB7S8qWxZTSIZH6x2I+wzdhSuZozLviQiwe9yws+FtZ3WWBa4BDw/EEbCo+D9sxu0ONz+dl7Mdxesnr+Rae80H9L5TfMxTlkef7GOCGGu2+DRuNl31+T2C+7qML7+8U7vEfsdHrciV134CFDwDb7HNUuKcTgfkt3Nesf7Na7R+wIebOXNa31bEfrx1KyrbAdEOyb7n31sIWu2v3re6zk716PnIvmlakIpWdyMhIhYWNfmMzi6m8irLBFKlhk74LeDM2XS5bULwRi+C5EuWxbTYk7k0RXXDEfsRin48A/60WfqHYtydUdZ2a96HtkXmqPGZWarpZTfpdWQeZZer0L5zX1qxyKJAW3Vjz9CS2TJlpRfrjs7wsIhOLXy5ga2xL8WwROZNy5XcvsJKIHE258noCWE5E9qZc+T0L/DVRfyzx2Cip2CwHA2eJSFk2mIPpzwZzIvFkCLeISDGZwT70Z4M5U0SK2WAm058Npqr+ROCm8ENZ5secKY9SsxkRcjbpfVI2aRm4oPg3TFkdomFBEVPagxQsNoPaR0S+h93vsgXHbMHsNao6A0BVHxaRZbDnKPb5jMdGlmVU2sjbQNopz5mV/oF9x8Ce2SPFfLx/n3i+o2SfkY21BpX9CfMWKSu7F9i5FbOaqj6JPZNRCgow69/Xc+W1+if9nkJlZctis8Nfquo5FecMiRuriAxwY62j2KFHNneJZ4P5AvZlHJGpsDBXq2RsFhmh2WByyqNqzWBx2aRTC45Vfua1FhyH+vMpG1kWyg/WkDtARFZT1aerygvvP6yqbyyO7nIz34n0P9+rh+JuunqmFOCx2Oj+j5TPzBTzerq1pG7Sjx8zy7XVP0l7CqVmlT11Yx3Unx4p92RwqhGs/LoSm6Xiuj3PBlPDbLY+FrO+bGS5raq+pur6BXkp5TckC45qoZRTYV3bmrmEullkwLWxxcMjsMXJBzE7c9HFUDAPlC3C/xOz64R2nobNan+H2YRvIGJW0oQrZI32D2uzWqsKsKKPk7DBZJ1Z5bBxYx3Ujx4p9yFRgMNE+bUdm6WGwup5Nhjg+4xwm3SsXEQOJB6VcEviM5cvYd4aY7Ep+MU52Vmo3Wuwxd0PYuGBL8Gel52wWUXR5Dc2XEuB57Q/5ve52Kj0+8D7sQXhk4gkuFbVu7tgVqtUULlzowouRcKsFlWA7fQv37cabet0Vjmkbqx98nqk3NtSgCNB+WmLqbCGG5JIhoCZniqVB2aTfkBLfLpFZE9VvbLVdrRZHvNzji44Eo9KSGLmMgtT8ncAH8F2TX8wjDTvgQG+0I+r6ro5GfeFdu0EfE5D/BTJuQIWPp/7dKDbYd9x1cy36WY1bLG3qn/PYWk6B4mltb71bFZZp30ZPVlQVdUXMQVxVov1oivYMcUeyqMpvmKKPasfvqBfCW99A8vh2qf8RGQaNRaMgBkMw2wwheYOSoYQZi7bRMxmgzJM5e5fLcWe3Ya65VJik8bcZgdXSi84ppKFPC/xBf/X55TalSLyReBXYaoPAxdjLyjIWEJVvxlmtt8W860+vtCe1cQ2EgmwgohI9rlmssPnuwO5z1dEss/3vRU/TpdhP06HU21WW6nkvSpS3i2DkvHUQVW/I+YP/zNsgLEkZsq5Evtezo707xXMJt5p34ZsRKyq08OPecfeOr3ylqmzYr4W5s88opQftuD7C7HNHlWLKm/CpuWDMt0wArLBJJRHRzbpHFUhHlYJ/54b/hfgLjFXO8meKa1IZE5QbmILjr/Jyc2U21eAe8QCiJVFJZxF3JvmIhFZQoMnlqp+VUQWYvbk5YDzJcRgUdVjc9d/A/2uvguBvcMPwg3YYCDj+5hSAxtlrwosCj+291WYlfKf7wuJH6cHsX0ApWa1intaRk8UoIjE+vdvutO3ISN8d9YJ38F2vzsmq0dmmViS5W2xL8HfgcdDlbHYlKqo/NrJBFOp/IL8MuXXcoLlKpsjZgo4tGi+kRGSDQb7XIbSJn1SkP8KtjmpuOD4B+I26U9qhwuOUiOqYcTscSrmDndjQf4uRDypqggDhtdrRbC6kvNTZqXJNNustmWkf1eE8zrtW8os01Z5bla5EZDZ1/u+O6p6VJ329cnrhXLvu3i5AjwV82cekcpP0wmWM2+gQTZHGQHZYGooj05t0k8TX3D8NfVt0i0vOGIbcKJfihZmdlX1ozObTsrFNuIlP9+IWa0rtKLgysxqUu3qWUsBDmX/JLGJSIbIjbXlgUEvlXsZMtAXfIACHAnKr0b/smwwG2GhC2BkZYN5FDhWVc8tlGX393ni3jQv68BFwC8C78V8i2+A+IKjqm4uImOxzTKZTfp+DTsYpfMFx5vpH+E9nqu7NBYK40TMxnsFJTMXVb0goXxTC5raYfk9pJNlDJmrZ+5+lSrAnFltP+xHe4Crp6b97JMKMNa/xGezAp3NKoeVG+twVO75VFgnYb7AI0n5JVNhSSTTTSgfztlgHgDeGrk/s4iPjC/CZl6v5O7HQZiZbjnM1W+z8P5XdKBdepaGwEzheFJo6zhVXSO8txD70ghwGGbS0Hz9xJd/NDaj2B8zUTyHzRaXCH3eGdg8MnOZRlz57pqY2Wgn5UG5xT7foXb17KlZDXNyqOrfPGzmXtW3sXQ2qxxyN1ZaYNgpd+hTfo1OhZWyOVbUGRbZYFL3N5zTlk0a+7KcWuyn2ILjyaq6V+H9ATZpESl6TJ2pqtmC46nYJppK5aaqfR4sYtu+V8UCgmWj2qjZg7RyTs1stMPyTWNmpVeBWe3iSP/+pKpLR/r2z05mlQyxG2vLaIsRyRbni0Tku5LzB0Vk61I7JpVdC3gHNr3cE9iwpqxUVMSPYHFpyuo+jj3Il2Jfki+Qi+CIuYO9CQtVew02A/oRNvq8i//f3rnH3lFUcfzzhfKIkBREQgzPSASjgIXGGp8RYwT+MIqigAQLPmIAQQWioWjUBEkUQSNIFQxQ8ZUg8QEkPO2PICBBoS0vAemPh6JoIlaUl8L4x8yl23t3Z+bevdu9uz2f5Jfe356Z3Tm9vz07c+bsOd4V9P6Sn78OPmeMfzAhuDzSZiF+BXMyfrZ1OLDdFL+Pg/A3+K/wqVyXAwdn9r2/bCz4bJelGSGH2i3Fu6aWh///ZfiUrw/ho2XW4Jffw/2W4Fc9B+CN6L34B8y1+Fntbfhsi3Xlc/jZ8m5D198Sn3JjHXBcxXf2YMb4Vw0dPx24GdgB7xK6syB7dKjtqvDvLvj0v+fgjfTaQps7htuX/Y4PfFiMn4AUM1w+ACys0O+5hG734cNRh7/ve/Az8tWF42cMtVuToduf8PfEKfhUBSrpP7V7p5VQyBgqlMKCDeNRM9we90p6Cw2UwpK0ANZXgnF+ZjkX0aPqJY7zwzV3knQZozP/tcAtGi2KIPwD5SI2LIZwo6T3OJ84aXf8w2NQDebX+JDCY/HVYM6jvBrMNvglpcPHD8dYKelyvN+5qG/MJ/1SKJ5L+KTDuSbxWZ8k6RDn3KcT50/FsUdxzq2QD1MrrlzmgNOcX9lFQyVd+j0B6sjDCuij+NDZMrfSN4BTJe1HM6GexRnzSBx/6BML9awbx/9VqkNZzwTOjeh2OOvrFRDGukLSE/hV5S/VYhirK6wqc5g5t8yQ2+Mp/FK3M6WwlFksoMrtoRmvBlPwSX8df1NM2yed2jBM+ayvSvRPbjgm9C8am8o2+L2fUuMc8/lPQ164zohbKRzvtVstwy3beN6qMt0y2kddZmV/99HztWHcCwawshpMh43foMboUW59VZZJaozOfDUY4I1M3yedkqd81lvF+rvEhmOG3nPEo2mW4icW/6B8wza1oUkdeWp2l/lwqhXqmSK1ckv0Te0Z7B3TL+PB2ViYakqeundcF0IhVaPI8qwbP60vFjCyYarxiiFc50ZTqiaLIeAfStEC0oVjE9UYDX2rXsRYSjza6GTqbRguJb6hdnGif3TDMbStNIBKR9M8gneDVRnn04kbJ1dHnprdZTycaoV6hnNNHArqEm61jMnDnyP6fQUfUXc73v5soBvpSKG6Yaq1w1gZg7aM+8TVYGbd+Mn7+q4HjnYhLlUbscZoE2jMajCxmbHibxAej78BkuFgEbdB6vxnk555r8y5kcrcHhkzS0isbOrIU7O7jIdTp91q+GCDKv0W4l20N1XoRs1VZS153VXlCG5KEQzj/OC/mM8BOxWO7YSfJV+feY6xImka1meHwudBjdFHqVdjdEQ/8mqMXgQcEZFfCZxQIUvWGM0Yv3LaUBHtUGhTKScjoqCqP37/5nh8hMfj+KiT+aDfhXjDVudvIRat8SDpaJta8jHHugXe7bndGONP1ZhNyVPRONH+hXvsCHzUyanh8/Yp/TJ0S42taXnWvZP7/bY1c9+eyaulDCrBrHCjbo/WSmERKsG4oRXDuKjj1WDq+qRD29hLRlGftfNug1objnVIuaWcf0M0teFXS97k+OmwWy1Dt9QLeNFV5RTkU1tVQktumTp0wfjV2TAq6NnJajBT8ElDfEMx5bM+I9bfjRlONgkJt1R0QzMs0alqk5IP2qQMYI3xd9qtlvNgrBpb0/KMe+c7zrlVZXqV6tqWca9rAGfV+AE3kNgwiujUq2owE/qkUxuKEPdJRxPHuTHDycYlw3jPETdOP8bv2SybUD7W7G7c8Q/aEAn1DG0qDVzOyqoJA5ipW6NhqhtzVdmWWya5Y17Rb+aNH96wxDZVDq+6JD2sBlNy7mSoZEJ+BvGl9bJYf1cz8VuKDON9LF7HPSk3ThfiJxVVxislH2t2N8H4O+tWy9AtGikUfm8tjHVc2jLusSLLj+Bn9CNiOmD88C9RxXyGr2U6BaRbqTFalwy/p4vJUz7rHJ/3tHUa0i97ZpkyTnXlDY2/s261DN1SkUK1wlRT8mmvKtsy7muoNoC3ASvpqPHL8BmuYMYLSCtSDCFnbClSfs86Puuc828smjC+G5M+u9UqdKu7qmw0jHVc2sotcwzV+SseosOlsFwid4ikL7NhHc0ilW6ismE0IVeixmhszyCHYJyfxMcjl8rxqVFL5azPbTNxREHOA2IaBBfWX5q+TlNUjD8nN09MnipjuCzj/LWp0C2Wl2awqmxSPlXarsQ0YgAlHcZ0yny1Vgor12dYB3WkGkzJ+eeot6GY8lnvj18dTSWczNiQTcCt1miY6sZcVbYZLdN0/opWjB/+Dzy1YbTJVIMZJsPvmb1hWLG0nmo4mTFKX91qqbGFe3ziMNWUPGcM49CWzz2VPOkJOmr88HmzYz7H1OvbvaoGE6PpDcOu+7xnkSkYwDlqvqjTlFttCqvKVsNYR/RpybjHNmXW4jfyOmn8wrXqZEXsVzUYo1f02a02hVVlq2GsI7gJc2jU+SGe4+H5ij6D3BS1KsHgc1FcDexbOD5f+Fy3EsxS6lXq6VU1GPvp1w/p3DxLEvJFhXOV5bZpNPfPGHqOjG1jyqfx09bMPbZpsiXwAVft9lhAzQLLknbBV2N6DO/CWe1C1kfVLLAc2tV5fftwplQMQeUFpL809HVMXGPU2LQxt9ps0+aGaqkBxC9XOmv8gEtd4j81uGCir29PC7VcDcYwjHZoa+aes2PeyVJY+Fl83de3e1MNxjCMdmjLuM8RN4Afx282/JGOGT98LvY6r2/3qhqMYRjt0JZxj+1Kz+N30q+k48avIg47WamnzPVRiKZxTcrdtKvBGIbRCq3ncx82gH03fhkz/1QBaNewvFaNUcMwZoO2csu8hBvN8ZDKXfGMpCXDxgn/otGzgGtSHgxbZW4USBq/VP6KNVTn3TmGUAyhQXlW7hbgkir9DcNon9Zn7sMkwiR7UQorZ+af2lBuSp7xIoe9vm8YHWDmjDv02/hlRgr1phqMYRjtMHPGve/GLyNSqFfVYAzDaIdZNO5z9Nj4Zcz8e1UNxjCMdmh9Q7WEg/HG7yeSyozfrsBeCeO1uEF5LePunHsWOB84vyJU8gHqFUOYhtwwjI4zc8Z9UzJ+JZFC0LNqMIZhtMPMuWVSZETTuCblG+MNzdSGctNywzC6T+eMO/Tb+KU2lMPLVFS1qSvPGYNhGLNP54x7341fxoZyp6rBGIbRDpu1PYAJWCnpREm7FQ9K2lLSO/E+7EubkktagTeATXEw8AJ+Q/lxSfdKmsfntTkSX5Hplgbl3zTDbhjdp4sz936VwoqQiqNvWm4YRnfpnHEvYsbPMAyjnE4bd8MwDKOcLvrcDcMwjARm3A3DMHqIGXfDMIweYsbdaARJ/07I95CUVZS80OcSSYeN0X7sa8wyOfr0TWdjcsy4G8YUkTRz+ZqMTRMz7kajSNpW0g2S7pB0l6T3FsQLJK2QtEbSzyS9LPRZLOlGSb+XdI2kV5act7RNOL5a0q3ACYmxHSPpvMLvV0p6h6TNwyrh7jDmzwb5npKuDte8SdJrwvFLJJ0jaSXwtZJr/ELSFZLmJX1K0smS7pT0W0kvD+0Whd/XSPp5SIFRqU8Y41mSbg99PjnO92L0HzPuRtM8CxzqnDsAOBA4e5DiAZ+X/wLn3H6EMobh3YJzgcOcc4uBi/CZMl8i0eZi4CTn3JtqjHkRsLNzbh/n3L7hnAAXACeGa56Kz146YC/gXc65U0rOtw/wYWBJGOfTzrn9gVuBj4Q2PwA+H/4v7sLXFIjp8zFgnXPuDfj6vp+QT5FtGMAMpvw1eoeAMyW9HZ82eWdgpyB7zDl3c/j8Q+Ak4Gq8MbwuPAM2ZzQt8t5lbeQraG3nnLsxtLsUOGSCMa8FXiXpXOAq4FpJ2wJvBi5b/2xiq0Kfy5xzL1Scb6Vz7ingKUnrgCvC8buA/UrGvSJcJ6bPu0PfwR7EQuDVwAMT6Gv0EDPuRtMcBeyIL4DyX0kPA1sH2fAbdA7/MLgnMfMubSNpu5JzxvgfG65etwZwzj0p6fX4zKAnAB8CPgP80zm3qOJc/4lc57nC5xcLv79I/B4U1foIv4q4ZoOD0h6R8xmbEOaWMZpmIfC3YNgPBHYvyHaTNDDQRwK/Ae4Hdhwcl7SFpNcNnbO0TUgRsU7SW0O7oxJjexhYJGkzSbvi3SZIegWwmXPucuCLwAHOuX8B85I+GNooPABGkLREUnbFLufcOuBJSW8Lh44Gbkzocw1wXHBRIWkvSdvkXtPoPzZzN5rmR8AVkn4HrAL+UJDdByyV9D18Vsrlzrnng6vh28EtsQD4FnDPaPIRngAAAKlJREFUoFOizbHARZKexhvAGDcD83j3yN3AHeH4zsDFkgaTn9PCv0cByyV9AdgC+CmwuuS8uwHPJK49zFLgu2FTeW3Qg4g+3wf2wFfVEvB34H1jXtPoMZZbxjCmjKSzgEudc2vaHoux6WLG3TAMo4eYW8boPZIOYij+HJh3zh3axngMY2NgM3fDMIweYtEyhmEYPcSMu2EYRg8x424YhtFDzLgbhmH0kP8DWssP3DPL/t0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_VJmrs6JHdA",
        "colab_type": "code",
        "outputId": "6441f3b9-c676-4c36-8576-979591ed4619",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from src import control_model\n",
        "m = control_model.random_model()\n",
        "m.fit(X,y)\n",
        "m.predict(X)\n",
        "\n",
        "from src.evaluation import cv\n",
        "cv(m, X, y)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "k_hold = 1/5\n",
            "k_hold = 2/5\n",
            "k_hold = 3/5\n",
            "k_hold = 4/5\n",
            "k_hold = 5/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'each_k_hold': defaultdict(list,\n",
              "             {'MAE': [1.4869791494544293,\n",
              "               1.4964069126075874,\n",
              "               1.4809219624002523,\n",
              "               1.4981259527291442,\n",
              "               1.4914129964960763],\n",
              "              'hit_top_100_precision': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
              "              'hit_top_100_recall': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
              "              'hit_top_10_precision': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
              "              'hit_top_10_recall': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
              "              'hit_top_20_precision': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
              "              'hit_top_20_recall': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
              "              'hit_top_30_precision': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
              "              'hit_top_30_recall': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
              "              'hit_top_40_precision': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
              "              'hit_top_40_recall': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
              "              'hit_top_50_precision': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
              "              'hit_top_50_recall': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
              "              'hit_top_5_precision': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
              "              'hit_top_5_recall': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
              "              'metrics_by_labeled_item': [                  abs_error  hit_top_5  ...  hit_top_100  n_sample\n",
              "               labeled_item                            ...                       \n",
              "               000_(0.0, 0.0)     1.465320        0.0  ...          0.0      7295\n",
              "               001_(0.0, 10.0]    1.490080        0.0  ...          0.0     14719\n",
              "               002_(10.0, 20.0]   1.504108        0.0  ...          0.0      3335\n",
              "               003_(20.0, 30.0]   1.478098        0.0  ...          0.0      1636\n",
              "               004_(30.0, 40.0]   1.474110        0.0  ...          0.0      1007\n",
              "               005_(40.0, 50.0]   1.524138        0.0  ...          0.0       585\n",
              "               006_(50.0, inf]    1.523436        0.0  ...          0.0      1673\n",
              "               \n",
              "               [7 rows x 9 columns],\n",
              "                                 abs_error  hit_top_5  ...  hit_top_100  n_sample\n",
              "               labeled_item                            ...                       \n",
              "               000_(0.0, 0.0)     1.469468        0.0  ...          0.0      7412\n",
              "               001_(0.0, 10.0]    1.494660        0.0  ...          0.0     14796\n",
              "               002_(10.0, 20.0]   1.541789        0.0  ...          0.0      3157\n",
              "               003_(20.0, 30.0]   1.499326        0.0  ...          0.0      1588\n",
              "               004_(30.0, 40.0]   1.553116        0.0  ...          0.0      1257\n",
              "               005_(40.0, 50.0]   1.547397        0.0  ...          0.0       752\n",
              "               006_(50.0, inf]    1.471544        0.0  ...          0.0      1288\n",
              "               \n",
              "               [7 rows x 9 columns],\n",
              "                                 abs_error  hit_top_5  ...  hit_top_100  n_sample\n",
              "               labeled_item                            ...                       \n",
              "               000_(0.0, 0.0)     1.460613        0.0  ...          0.0      7169\n",
              "               001_(0.0, 10.0]    1.483458        0.0  ...          0.0     15039\n",
              "               002_(10.0, 20.0]   1.500934        0.0  ...          0.0      3222\n",
              "               003_(20.0, 30.0]   1.524847        0.0  ...          0.0      1671\n",
              "               004_(30.0, 40.0]   1.456376        0.0  ...          0.0       865\n",
              "               005_(40.0, 50.0]   1.491115        0.0  ...          0.0       704\n",
              "               006_(50.0, inf]    1.470565        0.0  ...          0.0      1580\n",
              "               \n",
              "               [7 rows x 9 columns],\n",
              "                                 abs_error  hit_top_5  ...  hit_top_100  n_sample\n",
              "               labeled_item                            ...                       \n",
              "               000_(0.0, 0.0)     1.480493        0.0  ...          0.0      7304\n",
              "               001_(0.0, 10.0]    1.498727        0.0  ...          0.0     14345\n",
              "               002_(10.0, 20.0]   1.518912        0.0  ...          0.0      3282\n",
              "               003_(20.0, 30.0]   1.471541        0.0  ...          0.0      1794\n",
              "               004_(30.0, 40.0]   1.456619        0.0  ...          0.0      1033\n",
              "               005_(40.0, 50.0]   1.524201        0.0  ...          0.0       747\n",
              "               006_(50.0, inf]    1.568637        0.0  ...          0.0      1745\n",
              "               \n",
              "               [7 rows x 9 columns],\n",
              "                                 abs_error  hit_top_5  ...  hit_top_100  n_sample\n",
              "               labeled_item                            ...                       \n",
              "               000_(0.0, 0.0)     1.481676        0.0  ...          0.0      7297\n",
              "               001_(0.0, 10.0]    1.495227        0.0  ...          0.0     14459\n",
              "               002_(10.0, 20.0]   1.479201        0.0  ...          0.0      3061\n",
              "               003_(20.0, 30.0]   1.523862        0.0  ...          0.0      2076\n",
              "               004_(30.0, 40.0]   1.499402        0.0  ...          0.0      1288\n",
              "               005_(40.0, 50.0]   1.476316        0.0  ...          0.0       671\n",
              "               006_(50.0, inf]    1.481234        0.0  ...          0.0      1398\n",
              "               \n",
              "               [7 rows x 9 columns]],\n",
              "              'metrics_by_labeled_user': [                  abs_error  hit_top_5  ...  hit_top_100  n_sample\n",
              "               labeled_user                            ...                       \n",
              "               000_(0.0, 0.0)     1.443573        0.0  ...          0.0       383\n",
              "               002_(10.0, 20.0]   1.477660        0.0  ...          0.0      6017\n",
              "               003_(20.0, 30.0]   1.441740        0.0  ...          0.0      4749\n",
              "               004_(30.0, 40.0]   1.467092        0.0  ...          0.0      4213\n",
              "               005_(40.0, 50.0]   1.511157        0.0  ...          0.0      1507\n",
              "               006_(50.0, inf]    1.512006        0.0  ...          0.0     13381\n",
              "               \n",
              "               [6 rows x 9 columns],\n",
              "                                 abs_error  hit_top_5  ...  hit_top_100  n_sample\n",
              "               labeled_user                            ...                       \n",
              "               000_(0.0, 0.0)     1.480034        0.0  ...          0.0       403\n",
              "               001_(0.0, 10.0]    1.288870        0.0  ...          0.0        23\n",
              "               002_(10.0, 20.0]   1.467335        0.0  ...          0.0      6999\n",
              "               003_(20.0, 30.0]   1.498810        0.0  ...          0.0      4613\n",
              "               004_(30.0, 40.0]   1.487966        0.0  ...          0.0      3411\n",
              "               005_(40.0, 50.0]   1.490422        0.0  ...          0.0      2011\n",
              "               006_(50.0, inf]    1.515531        0.0  ...          0.0     12790\n",
              "               \n",
              "               [7 rows x 9 columns],\n",
              "                                 abs_error  hit_top_5  ...  hit_top_100  n_sample\n",
              "               labeled_user                            ...                       \n",
              "               000_(0.0, 0.0)     1.390994        0.0  ...          0.0       368\n",
              "               001_(0.0, 10.0]    1.258227        0.0  ...          0.0       210\n",
              "               002_(10.0, 20.0]   1.441960        0.0  ...          0.0      7323\n",
              "               003_(20.0, 30.0]   1.500741        0.0  ...          0.0      4361\n",
              "               004_(30.0, 40.0]   1.463031        0.0  ...          0.0      2077\n",
              "               005_(40.0, 50.0]   1.433592        0.0  ...          0.0      2618\n",
              "               006_(50.0, inf]    1.514008        0.0  ...          0.0     13293\n",
              "               \n",
              "               [7 rows x 9 columns],\n",
              "                                 abs_error  hit_top_5  ...  hit_top_100  n_sample\n",
              "               labeled_user                            ...                       \n",
              "               000_(0.0, 0.0)     1.462739        0.0  ...          0.0       405\n",
              "               002_(10.0, 20.0]   1.471737        0.0  ...          0.0      6326\n",
              "               003_(20.0, 30.0]   1.517882        0.0  ...          0.0      3893\n",
              "               004_(30.0, 40.0]   1.494074        0.0  ...          0.0      3890\n",
              "               005_(40.0, 50.0]   1.538793        0.0  ...          0.0      1924\n",
              "               006_(50.0, inf]    1.501158        0.0  ...          0.0     13812\n",
              "               \n",
              "               [6 rows x 9 columns],\n",
              "                                 abs_error  hit_top_5  ...  hit_top_100  n_sample\n",
              "               labeled_user                            ...                       \n",
              "               000_(0.0, 0.0)     1.465830        0.0  ...          0.0       371\n",
              "               001_(0.0, 10.0]    1.556485        NaN  ...          NaN        14\n",
              "               002_(10.0, 20.0]   1.475301        0.0  ...          0.0      5914\n",
              "               003_(20.0, 30.0]   1.513844        0.0  ...          0.0      4369\n",
              "               004_(30.0, 40.0]   1.506197        0.0  ...          0.0      3061\n",
              "               005_(40.0, 50.0]   1.518638        0.0  ...          0.0      1275\n",
              "               006_(50.0, inf]    1.486553        0.0  ...          0.0     15246\n",
              "               \n",
              "               [7 rows x 9 columns]],\n",
              "              'metrics_by_labeled_user_item': [                                   abs_error  hit_top_5  ...  hit_top_100  n_sample\n",
              "               labeled_user     labeled_item                            ...                       \n",
              "               000_(0.0, 0.0)   000_(0.0, 0.0)     1.348165        0.0  ...          0.0       222\n",
              "                                001_(0.0, 10.0]    1.474327        0.0  ...          0.0       130\n",
              "                                002_(10.0, 20.0]   1.781343        0.0  ...          0.0        14\n",
              "                                003_(20.0, 30.0]   1.776825        0.0  ...          0.0         5\n",
              "                                004_(30.0, 40.0]   3.424883        0.0  ...          0.0         4\n",
              "                                005_(40.0, 50.0]   2.761741        0.0  ...          0.0         3\n",
              "                                006_(50.0, inf]    1.225156        0.0  ...          0.0         5\n",
              "               002_(10.0, 20.0] 000_(0.0, 0.0)     1.499953        0.0  ...          0.0      1197\n",
              "                                001_(0.0, 10.0]    1.461768        0.0  ...          0.0      3058\n",
              "                                002_(10.0, 20.0]   1.435487        0.0  ...          0.0       712\n",
              "                                003_(20.0, 30.0]   1.604783        0.0  ...          0.0       338\n",
              "                                004_(30.0, 40.0]   1.403156        0.0  ...          0.0       224\n",
              "                                005_(40.0, 50.0]   1.491574        0.0  ...          0.0       129\n",
              "                                006_(50.0, inf]    1.544143        0.0  ...          0.0       359\n",
              "               003_(20.0, 30.0] 000_(0.0, 0.0)     1.457018        0.0  ...          0.0      1338\n",
              "                                001_(0.0, 10.0]    1.440978        0.0  ...          0.0      2253\n",
              "                                002_(10.0, 20.0]   1.438700        0.0  ...          0.0       472\n",
              "                                003_(20.0, 30.0]   1.479494        0.0  ...          0.0       239\n",
              "                                004_(30.0, 40.0]   1.442317        0.0  ...          0.0       134\n",
              "                                005_(40.0, 50.0]   1.324004        0.0  ...          0.0        85\n",
              "                                006_(50.0, inf]    1.369884        0.0  ...          0.0       228\n",
              "               004_(30.0, 40.0] 000_(0.0, 0.0)     1.389428        0.0  ...          0.0      1198\n",
              "                                001_(0.0, 10.0]    1.492574        0.0  ...          0.0      2054\n",
              "                                002_(10.0, 20.0]   1.528185        0.0  ...          0.0       406\n",
              "                                003_(20.0, 30.0]   1.383927        0.0  ...          0.0       183\n",
              "                                004_(30.0, 40.0]   1.522123        0.0  ...          0.0       107\n",
              "                                005_(40.0, 50.0]   1.604074        0.0  ...          0.0        73\n",
              "                                006_(50.0, inf]    1.546411        0.0  ...          0.0       192\n",
              "               005_(40.0, 50.0] 000_(0.0, 0.0)     1.500514        0.0  ...          0.0       314\n",
              "                                001_(0.0, 10.0]    1.512240        0.0  ...          0.0       716\n",
              "                                002_(10.0, 20.0]   1.462547        0.0  ...          0.0       179\n",
              "                                003_(20.0, 30.0]   1.372489        0.0  ...          0.0        87\n",
              "                                004_(30.0, 40.0]   1.594652        0.0  ...          0.0        74\n",
              "                                005_(40.0, 50.0]   1.619244        0.0  ...          0.0        35\n",
              "                                006_(50.0, inf]    1.642239        0.0  ...          0.0       102\n",
              "               006_(50.0, inf]  000_(0.0, 0.0)     1.490279        0.0  ...          0.0      3026\n",
              "                                001_(0.0, 10.0]    1.517471        0.0  ...          0.0      6508\n",
              "                                002_(10.0, 20.0]   1.551475        0.0  ...          0.0      1552\n",
              "                                003_(20.0, 30.0]   1.454852        0.0  ...          0.0       784\n",
              "                                004_(30.0, 40.0]   1.470433        0.0  ...          0.0       464\n",
              "                                005_(40.0, 50.0]   1.556197        0.0  ...          0.0       260\n",
              "                                006_(50.0, inf]    1.539367        0.0  ...          0.0       787\n",
              "               \n",
              "               [42 rows x 9 columns],\n",
              "                                                  abs_error  hit_top_5  ...  hit_top_100  n_sample\n",
              "               labeled_user     labeled_item                            ...                       \n",
              "               000_(0.0, 0.0)   000_(0.0, 0.0)     1.453510        0.0  ...          0.0       243\n",
              "                                001_(0.0, 10.0]    1.470188        0.0  ...          0.0       133\n",
              "                                002_(10.0, 20.0]   1.342458        0.0  ...          0.0        14\n",
              "                                003_(20.0, 30.0]   3.058641        0.0  ...          0.0         3\n",
              "                                004_(30.0, 40.0]   1.463530        NaN  ...          NaN         5\n",
              "                                005_(40.0, 50.0]   1.500501        0.0  ...          0.0         2\n",
              "                                006_(50.0, inf]    3.142313        0.0  ...          0.0         3\n",
              "               001_(0.0, 10.0]  001_(0.0, 10.0]    1.488477        0.0  ...          0.0        15\n",
              "                                002_(10.0, 20.0]   0.982589        0.0  ...          0.0         5\n",
              "                                003_(20.0, 30.0]   0.801303        0.0  ...          0.0         3\n",
              "               002_(10.0, 20.0] 000_(0.0, 0.0)     1.411027        0.0  ...          0.0      1540\n",
              "                                001_(0.0, 10.0]    1.469736        0.0  ...          0.0      3557\n",
              "                                002_(10.0, 20.0]   1.560948        0.0  ...          0.0       738\n",
              "                                003_(20.0, 30.0]   1.483656        0.0  ...          0.0       403\n",
              "                                004_(30.0, 40.0]   1.469388        0.0  ...          0.0       288\n",
              "                                005_(40.0, 50.0]   1.558305        0.0  ...          0.0       177\n",
              "                                006_(50.0, inf]    1.419422        0.0  ...          0.0       296\n",
              "               003_(20.0, 30.0] 000_(0.0, 0.0)     1.487408        0.0  ...          0.0       971\n",
              "                                001_(0.0, 10.0]    1.486317        0.0  ...          0.0      2324\n",
              "                                002_(10.0, 20.0]   1.566650        0.0  ...          0.0       500\n",
              "                                003_(20.0, 30.0]   1.546484        0.0  ...          0.0       268\n",
              "                                004_(30.0, 40.0]   1.555087        0.0  ...          0.0       216\n",
              "                                005_(40.0, 50.0]   1.375474        0.0  ...          0.0       124\n",
              "                                006_(50.0, inf]    1.482358        0.0  ...          0.0       210\n",
              "               004_(30.0, 40.0] 000_(0.0, 0.0)     1.471664        0.0  ...          0.0      1030\n",
              "                                001_(0.0, 10.0]    1.487446        0.0  ...          0.0      1533\n",
              "                                002_(10.0, 20.0]   1.529720        0.0  ...          0.0       339\n",
              "                                003_(20.0, 30.0]   1.567598        0.0  ...          0.0       166\n",
              "                                004_(30.0, 40.0]   1.422996        0.0  ...          0.0       129\n",
              "                                005_(40.0, 50.0]   1.536652        0.0  ...          0.0        71\n",
              "                                006_(50.0, inf]    1.453969        0.0  ...          0.0       143\n",
              "               005_(40.0, 50.0] 000_(0.0, 0.0)     1.407175        0.0  ...          0.0       590\n",
              "                                001_(0.0, 10.0]    1.523787        0.0  ...          0.0       896\n",
              "                                002_(10.0, 20.0]   1.574114        0.0  ...          0.0       190\n",
              "                                003_(20.0, 30.0]   1.572804        0.0  ...          0.0       102\n",
              "                                004_(30.0, 40.0]   1.454063        0.0  ...          0.0        78\n",
              "                                005_(40.0, 50.0]   1.516644        0.0  ...          0.0        64\n",
              "                                006_(50.0, inf]    1.447283        0.0  ...          0.0        91\n",
              "               006_(50.0, inf]  000_(0.0, 0.0)     1.505989        0.0  ...          0.0      3038\n",
              "                                001_(0.0, 10.0]    1.509864        0.0  ...          0.0      6338\n",
              "                                002_(10.0, 20.0]   1.524988        0.0  ...          0.0      1371\n",
              "                                003_(20.0, 30.0]   1.456191        0.0  ...          0.0       643\n",
              "                                004_(30.0, 40.0]   1.643038        0.0  ...          0.0       541\n",
              "                                005_(40.0, 50.0]   1.618139        0.0  ...          0.0       314\n",
              "                                006_(50.0, inf]    1.495150        0.0  ...          0.0       545\n",
              "               \n",
              "               [45 rows x 9 columns],\n",
              "                                                  abs_error  hit_top_5  ...  hit_top_100  n_sample\n",
              "               labeled_user     labeled_item                            ...                       \n",
              "               000_(0.0, 0.0)   000_(0.0, 0.0)     1.262855        0.0  ...          0.0       224\n",
              "                                001_(0.0, 10.0]    1.574109        0.0  ...          0.0       126\n",
              "                                002_(10.0, 20.0]   1.638032        0.0  ...          0.0        11\n",
              "                                003_(20.0, 30.0]   1.107901        0.0  ...          0.0         2\n",
              "                                004_(30.0, 40.0]   2.940586        0.0  ...          0.0         2\n",
              "                                005_(40.0, 50.0]   2.137895        0.0  ...          0.0         1\n",
              "                                006_(50.0, inf]    1.207762        0.0  ...          0.0         2\n",
              "               001_(0.0, 10.0]  000_(0.0, 0.0)     1.402518        0.0  ...          0.0        96\n",
              "                                001_(0.0, 10.0]    1.149191        0.0  ...          0.0        87\n",
              "                                002_(10.0, 20.0]   0.859373        0.0  ...          0.0         8\n",
              "                                003_(20.0, 30.0]   1.315512        NaN  ...          NaN         7\n",
              "                                004_(30.0, 40.0]   0.919896        NaN  ...          NaN         5\n",
              "                                005_(40.0, 50.0]   1.553326        0.0  ...          0.0         5\n",
              "                                006_(50.0, inf]    0.578369        NaN  ...          NaN         2\n",
              "               002_(10.0, 20.0] 000_(0.0, 0.0)     1.410256        0.0  ...          0.0      1684\n",
              "                                001_(0.0, 10.0]    1.445285        0.0  ...          0.0      3745\n",
              "                                002_(10.0, 20.0]   1.467599        0.0  ...          0.0       793\n",
              "                                003_(20.0, 30.0]   1.529280        0.0  ...          0.0       411\n",
              "                                004_(30.0, 40.0]   1.444951        0.0  ...          0.0       212\n",
              "                                005_(40.0, 50.0]   1.525239        0.0  ...          0.0       145\n",
              "                                006_(50.0, inf]    1.357906        0.0  ...          0.0       333\n",
              "               003_(20.0, 30.0] 000_(0.0, 0.0)     1.503173        0.0  ...          0.0      1110\n",
              "                                001_(0.0, 10.0]    1.488734        0.0  ...          0.0      2119\n",
              "                                002_(10.0, 20.0]   1.579494        0.0  ...          0.0       475\n",
              "                                003_(20.0, 30.0]   1.539755        0.0  ...          0.0       234\n",
              "                                004_(30.0, 40.0]   1.412637        0.0  ...          0.0       106\n",
              "                                005_(40.0, 50.0]   1.388666        0.0  ...          0.0       108\n",
              "                                006_(50.0, inf]    1.489496        0.0  ...          0.0       209\n",
              "               004_(30.0, 40.0] 000_(0.0, 0.0)     1.432645        0.0  ...          0.0       369\n",
              "                                001_(0.0, 10.0]    1.475790        0.0  ...          0.0      1052\n",
              "                                002_(10.0, 20.0]   1.488152        0.0  ...          0.0       257\n",
              "                                003_(20.0, 30.0]   1.447513        0.0  ...          0.0       120\n",
              "                                004_(30.0, 40.0]   1.335270        0.0  ...          0.0        65\n",
              "                                005_(40.0, 50.0]   1.452723        0.0  ...          0.0        57\n",
              "                                006_(50.0, inf]    1.476332        0.0  ...          0.0       157\n",
              "               005_(40.0, 50.0] 000_(0.0, 0.0)     1.412859        0.0  ...          0.0       696\n",
              "                                001_(0.0, 10.0]    1.438079        0.0  ...          0.0      1246\n",
              "                                002_(10.0, 20.0]   1.404883        0.0  ...          0.0       279\n",
              "                                003_(20.0, 30.0]   1.473653        0.0  ...          0.0       118\n",
              "                                004_(30.0, 40.0]   1.578146        0.0  ...          0.0        72\n",
              "                                005_(40.0, 50.0]   1.260122        0.0  ...          0.0        69\n",
              "                                006_(50.0, inf]    1.532742        0.0  ...          0.0       138\n",
              "               006_(50.0, inf]  000_(0.0, 0.0)     1.504422        0.0  ...          0.0      2990\n",
              "                                001_(0.0, 10.0]    1.515578        0.0  ...          0.0      6664\n",
              "                                002_(10.0, 20.0]   1.517251        0.0  ...          0.0      1399\n",
              "                                003_(20.0, 30.0]   1.540649        0.0  ...          0.0       779\n",
              "                                004_(30.0, 40.0]   1.470958        0.0  ...          0.0       403\n",
              "                                005_(40.0, 50.0]   1.564110        0.0  ...          0.0       319\n",
              "                                006_(50.0, inf]    1.506266        0.0  ...          0.0       739\n",
              "               \n",
              "               [49 rows x 9 columns],\n",
              "                                                  abs_error  hit_top_5  ...  hit_top_100  n_sample\n",
              "               labeled_user     labeled_item                            ...                       \n",
              "               000_(0.0, 0.0)   000_(0.0, 0.0)     1.433018        0.0  ...          0.0       237\n",
              "                                001_(0.0, 10.0]    1.541835        0.0  ...          0.0       139\n",
              "                                002_(10.0, 20.0]   1.003673        0.0  ...          0.0        15\n",
              "                                003_(20.0, 30.0]   1.606960        NaN  ...          NaN         7\n",
              "                                004_(30.0, 40.0]   0.336467        0.0  ...          0.0         2\n",
              "                                005_(40.0, 50.0]   3.119367        0.0  ...          0.0         2\n",
              "                                006_(50.0, inf]    1.751198        NaN  ...          NaN         3\n",
              "               002_(10.0, 20.0] 000_(0.0, 0.0)     1.381707        0.0  ...          0.0      1341\n",
              "                                001_(0.0, 10.0]    1.489682        0.0  ...          0.0      3153\n",
              "                                002_(10.0, 20.0]   1.494024        0.0  ...          0.0       728\n",
              "                                003_(20.0, 30.0]   1.441530        0.0  ...          0.0       361\n",
              "                                004_(30.0, 40.0]   1.474310        0.0  ...          0.0       233\n",
              "                                005_(40.0, 50.0]   1.503860        0.0  ...          0.0       158\n",
              "                                006_(50.0, inf]    1.622744        0.0  ...          0.0       352\n",
              "               003_(20.0, 30.0] 000_(0.0, 0.0)     1.619259        0.0  ...          0.0       810\n",
              "                                001_(0.0, 10.0]    1.473781        0.0  ...          0.0      1916\n",
              "                                002_(10.0, 20.0]   1.554809        0.0  ...          0.0       422\n",
              "                                003_(20.0, 30.0]   1.462338        0.0  ...          0.0       242\n",
              "                                004_(30.0, 40.0]   1.507646        0.0  ...          0.0       162\n",
              "                                005_(40.0, 50.0]   1.488375        0.0  ...          0.0       102\n",
              "                                006_(50.0, inf]    1.538421        0.0  ...          0.0       239\n",
              "               004_(30.0, 40.0] 000_(0.0, 0.0)     1.503258        0.0  ...          0.0       895\n",
              "                                001_(0.0, 10.0]    1.492640        0.0  ...          0.0      1891\n",
              "                                002_(10.0, 20.0]   1.503384        0.0  ...          0.0       426\n",
              "                                003_(20.0, 30.0]   1.418951        0.0  ...          0.0       231\n",
              "                                004_(30.0, 40.0]   1.470721        0.0  ...          0.0       127\n",
              "                                005_(40.0, 50.0]   1.555419        0.0  ...          0.0        94\n",
              "                                006_(50.0, inf]    1.516536        0.0  ...          0.0       226\n",
              "               005_(40.0, 50.0] 000_(0.0, 0.0)     1.464359        0.0  ...          0.0       682\n",
              "                                001_(0.0, 10.0]    1.557165        0.0  ...          0.0       760\n",
              "                                002_(10.0, 20.0]   1.646206        0.0  ...          0.0       194\n",
              "                                003_(20.0, 30.0]   1.643790        0.0  ...          0.0       116\n",
              "                                004_(30.0, 40.0]   1.363468        0.0  ...          0.0        55\n",
              "                                005_(40.0, 50.0]   1.538740        0.0  ...          0.0        38\n",
              "                                006_(50.0, inf]    1.708784        0.0  ...          0.0        79\n",
              "               006_(50.0, inf]  000_(0.0, 0.0)     1.487067        0.0  ...          0.0      3339\n",
              "                                001_(0.0, 10.0]    1.504496        0.0  ...          0.0      6486\n",
              "                                002_(10.0, 20.0]   1.513982        0.0  ...          0.0      1497\n",
              "                                003_(20.0, 30.0]   1.476656        0.0  ...          0.0       837\n",
              "                                004_(30.0, 40.0]   1.441606        0.0  ...          0.0       454\n",
              "                                005_(40.0, 50.0]   1.524741        0.0  ...          0.0       353\n",
              "                                006_(50.0, inf]    1.554844        0.0  ...          0.0       846\n",
              "               \n",
              "               [42 rows x 9 columns],\n",
              "                                                  abs_error  hit_top_5  ...  hit_top_100  n_sample\n",
              "               labeled_user     labeled_item                            ...                       \n",
              "               000_(0.0, 0.0)   000_(0.0, 0.0)     1.494436        0.0  ...          0.0       227\n",
              "                                001_(0.0, 10.0]    1.369136        0.0  ...          0.0       110\n",
              "                                002_(10.0, 20.0]   1.494031        0.0  ...          0.0        16\n",
              "                                003_(20.0, 30.0]   2.184640        0.0  ...          0.0         7\n",
              "                                004_(30.0, 40.0]   1.508291        0.0  ...          0.0         6\n",
              "                                005_(40.0, 50.0]   0.974602        NaN  ...          NaN         2\n",
              "                                006_(50.0, inf]    1.261632        0.0  ...          0.0         3\n",
              "               001_(0.0, 10.0]  001_(0.0, 10.0]    0.381337        NaN  ...          NaN         1\n",
              "                                002_(10.0, 20.0]   1.722569        NaN  ...          NaN         5\n",
              "                                003_(20.0, 30.0]   2.024467        NaN  ...          NaN         4\n",
              "                                004_(30.0, 40.0]   0.972229        NaN  ...          NaN         2\n",
              "                                005_(40.0, 50.0]   1.136992        NaN  ...          NaN         1\n",
              "                                006_(50.0, inf]    1.617294        NaN  ...          NaN         1\n",
              "               002_(10.0, 20.0] 000_(0.0, 0.0)     1.454431        0.0  ...          0.0      1386\n",
              "                                001_(0.0, 10.0]    1.483790        0.0  ...          0.0      2813\n",
              "                                002_(10.0, 20.0]   1.504920        0.0  ...          0.0       624\n",
              "                                003_(20.0, 30.0]   1.506769        0.0  ...          0.0       423\n",
              "                                004_(30.0, 40.0]   1.588103        0.0  ...          0.0       262\n",
              "                                005_(40.0, 50.0]   1.386852        0.0  ...          0.0       140\n",
              "                                006_(50.0, inf]    1.310184        0.0  ...          0.0       266\n",
              "               003_(20.0, 30.0] 000_(0.0, 0.0)     1.533924        0.0  ...          0.0      1022\n",
              "                                001_(0.0, 10.0]    1.488292        0.0  ...          0.0      2129\n",
              "                                002_(10.0, 20.0]   1.585146        0.0  ...          0.0       432\n",
              "                                003_(20.0, 30.0]   1.501501        0.0  ...          0.0       317\n",
              "                                004_(30.0, 40.0]   1.523282        0.0  ...          0.0       193\n",
              "                                005_(40.0, 50.0]   1.599668        0.0  ...          0.0        93\n",
              "                                006_(50.0, inf]    1.498462        0.0  ...          0.0       183\n",
              "               004_(30.0, 40.0] 000_(0.0, 0.0)     1.478211        0.0  ...          0.0       836\n",
              "                                001_(0.0, 10.0]    1.530190        0.0  ...          0.0      1426\n",
              "                                002_(10.0, 20.0]   1.500778        0.0  ...          0.0       299\n",
              "                                003_(20.0, 30.0]   1.578557        0.0  ...          0.0       188\n",
              "                                004_(30.0, 40.0]   1.499314        0.0  ...          0.0       121\n",
              "                                005_(40.0, 50.0]   1.318347        0.0  ...          0.0        62\n",
              "                                006_(50.0, inf]    1.426183        0.0  ...          0.0       129\n",
              "               005_(40.0, 50.0] 000_(0.0, 0.0)     1.414734        0.0  ...          0.0       391\n",
              "                                001_(0.0, 10.0]    1.595336        0.0  ...          0.0       530\n",
              "                                002_(10.0, 20.0]   1.380727        0.0  ...          0.0       115\n",
              "                                003_(20.0, 30.0]   1.498039        0.0  ...          0.0        87\n",
              "                                004_(30.0, 40.0]   1.716533        0.0  ...          0.0        59\n",
              "                                005_(40.0, 50.0]   1.592496        0.0  ...          0.0        32\n",
              "                                006_(50.0, inf]    1.577485        0.0  ...          0.0        61\n",
              "               006_(50.0, inf]  000_(0.0, 0.0)     1.484743        0.0  ...          0.0      3435\n",
              "                                001_(0.0, 10.0]    1.489723        0.0  ...          0.0      7450\n",
              "                                002_(10.0, 20.0]   1.442006        0.0  ...          0.0      1570\n",
              "                                003_(20.0, 30.0]   1.523533        0.0  ...          0.0      1050\n",
              "                                004_(30.0, 40.0]   1.437932        0.0  ...          0.0       645\n",
              "                                005_(40.0, 50.0]   1.501162        0.0  ...          0.0       341\n",
              "                                006_(50.0, inf]    1.539644        0.0  ...          0.0       755\n",
              "               \n",
              "               [48 rows x 9 columns]]}),\n",
              " 'total_mean': {'MAE': 1.490769394737498,\n",
              "  'hit_top_100_precision': 0.0,\n",
              "  'hit_top_100_recall': 0.0,\n",
              "  'hit_top_10_precision': 0.0,\n",
              "  'hit_top_10_recall': 0.0,\n",
              "  'hit_top_20_precision': 0.0,\n",
              "  'hit_top_20_recall': 0.0,\n",
              "  'hit_top_30_precision': 0.0,\n",
              "  'hit_top_30_recall': 0.0,\n",
              "  'hit_top_40_precision': 0.0,\n",
              "  'hit_top_40_recall': 0.0,\n",
              "  'hit_top_50_precision': 0.0,\n",
              "  'hit_top_50_recall': 0.0,\n",
              "  'hit_top_5_precision': 0.0,\n",
              "  'hit_top_5_recall': 0.0,\n",
              "  'metrics_by_labeled_item':                   abs_error  hit_top_5  ...  hit_top_100  n_sample\n",
              "  labeled_item                            ...                       \n",
              "  000_(0.0, 0.0)     1.471514        0.0  ...          0.0    7295.4\n",
              "  001_(0.0, 10.0]    1.492430        0.0  ...          0.0   14671.6\n",
              "  002_(10.0, 20.0]   1.508989        0.0  ...          0.0    3211.4\n",
              "  003_(20.0, 30.0]   1.499535        0.0  ...          0.0    1753.0\n",
              "  004_(30.0, 40.0]   1.487925        0.0  ...          0.0    1090.0\n",
              "  005_(40.0, 50.0]   1.512633        0.0  ...          0.0     691.8\n",
              "  006_(50.0, inf]    1.503083        0.0  ...          0.0    1536.8\n",
              "  \n",
              "  [7 rows x 9 columns],\n",
              "  'metrics_by_labeled_user':                   abs_error  hit_top_5  ...  hit_top_100      n_sample\n",
              "  labeled_user                            ...                           \n",
              "  000_(0.0, 0.0)     1.448634        0.0  ...          0.0    386.000000\n",
              "  001_(0.0, 10.0]    1.367861        0.0  ...          0.0     82.333333\n",
              "  002_(10.0, 20.0]   1.466799        0.0  ...          0.0   6515.800000\n",
              "  003_(20.0, 30.0]   1.494603        0.0  ...          0.0   4397.000000\n",
              "  004_(30.0, 40.0]   1.483672        0.0  ...          0.0   3330.400000\n",
              "  005_(40.0, 50.0]   1.498520        0.0  ...          0.0   1867.000000\n",
              "  006_(50.0, inf]    1.505851        0.0  ...          0.0  13704.400000\n",
              "  \n",
              "  [7 rows x 9 columns],\n",
              "  'metrics_by_labeled_user_item':                                       abs_error  ...     n_sample\n",
              "  (000_(0.0, 0.0), 000_(0.0, 0.0))       1.398397  ...   230.600000\n",
              "  (000_(0.0, 0.0), 001_(0.0, 10.0])      1.485919  ...   127.600000\n",
              "  (000_(0.0, 0.0), 002_(10.0, 20.0])     1.451907  ...    14.000000\n",
              "  (000_(0.0, 0.0), 003_(20.0, 30.0])     1.946993  ...     4.800000\n",
              "  (000_(0.0, 0.0), 004_(30.0, 40.0])     1.934751  ...     3.800000\n",
              "  (000_(0.0, 0.0), 005_(40.0, 50.0])     2.098821  ...     2.000000\n",
              "  (000_(0.0, 0.0), 006_(50.0, inf])      1.717612  ...     3.200000\n",
              "  (001_(0.0, 10.0], 000_(0.0, 0.0))      1.402518  ...    96.000000\n",
              "  (001_(0.0, 10.0], 001_(0.0, 10.0])     1.006335  ...    34.333333\n",
              "  (001_(0.0, 10.0], 002_(10.0, 20.0])    1.188177  ...     6.000000\n",
              "  (001_(0.0, 10.0], 003_(20.0, 30.0])    1.380428  ...     4.666667\n",
              "  (001_(0.0, 10.0], 004_(30.0, 40.0])    0.946063  ...     3.500000\n",
              "  (001_(0.0, 10.0], 005_(40.0, 50.0])    1.345159  ...     3.000000\n",
              "  (001_(0.0, 10.0], 006_(50.0, inf])     1.097831  ...     1.500000\n",
              "  (002_(10.0, 20.0], 000_(0.0, 0.0))     1.431475  ...  1429.600000\n",
              "  (002_(10.0, 20.0], 001_(0.0, 10.0])    1.470052  ...  3265.200000\n",
              "  (002_(10.0, 20.0], 002_(10.0, 20.0])   1.492595  ...   719.000000\n",
              "  (002_(10.0, 20.0], 003_(20.0, 30.0])   1.513204  ...   387.200000\n",
              "  (002_(10.0, 20.0], 004_(30.0, 40.0])   1.475982  ...   243.800000\n",
              "  (002_(10.0, 20.0], 005_(40.0, 50.0])   1.493166  ...   149.800000\n",
              "  (002_(10.0, 20.0], 006_(50.0, inf])    1.450880  ...   321.200000\n",
              "  (003_(20.0, 30.0], 000_(0.0, 0.0))     1.520156  ...  1050.200000\n",
              "  (003_(20.0, 30.0], 001_(0.0, 10.0])    1.475620  ...  2148.200000\n",
              "  (003_(20.0, 30.0], 002_(10.0, 20.0])   1.544960  ...   460.200000\n",
              "  (003_(20.0, 30.0], 003_(20.0, 30.0])   1.505915  ...   260.000000\n",
              "  (003_(20.0, 30.0], 004_(30.0, 40.0])   1.488194  ...   162.200000\n",
              "  (003_(20.0, 30.0], 005_(40.0, 50.0])   1.435237  ...   102.400000\n",
              "  (003_(20.0, 30.0], 006_(50.0, inf])    1.475724  ...   213.800000\n",
              "  (004_(30.0, 40.0], 000_(0.0, 0.0))     1.455041  ...   865.600000\n",
              "  (004_(30.0, 40.0], 001_(0.0, 10.0])    1.495728  ...  1591.200000\n",
              "  (004_(30.0, 40.0], 002_(10.0, 20.0])   1.510044  ...   345.400000\n",
              "  (004_(30.0, 40.0], 003_(20.0, 30.0])   1.479309  ...   177.600000\n",
              "  (004_(30.0, 40.0], 004_(30.0, 40.0])   1.450085  ...   109.800000\n",
              "  (004_(30.0, 40.0], 005_(40.0, 50.0])   1.493443  ...    71.400000\n",
              "  (004_(30.0, 40.0], 006_(50.0, inf])    1.483886  ...   169.400000\n",
              "  (005_(40.0, 50.0], 000_(0.0, 0.0))     1.439928  ...   534.600000\n",
              "  (005_(40.0, 50.0], 001_(0.0, 10.0])    1.525321  ...   829.600000\n",
              "  (005_(40.0, 50.0], 002_(10.0, 20.0])   1.493695  ...   191.400000\n",
              "  (005_(40.0, 50.0], 003_(20.0, 30.0])   1.512155  ...   102.000000\n",
              "  (005_(40.0, 50.0], 004_(30.0, 40.0])   1.541373  ...    67.600000\n",
              "  (005_(40.0, 50.0], 005_(40.0, 50.0])   1.505449  ...    47.600000\n",
              "  (005_(40.0, 50.0], 006_(50.0, inf])    1.581706  ...    94.200000\n",
              "  (006_(50.0, inf], 000_(0.0, 0.0))      1.494500  ...  3165.600000\n",
              "  (006_(50.0, inf], 001_(0.0, 10.0])     1.507427  ...  6689.200000\n",
              "  (006_(50.0, inf], 002_(10.0, 20.0])    1.509941  ...  1477.800000\n",
              "  (006_(50.0, inf], 003_(20.0, 30.0])    1.490376  ...   818.600000\n",
              "  (006_(50.0, inf], 004_(30.0, 40.0])    1.492793  ...   501.400000\n",
              "  (006_(50.0, inf], 005_(40.0, 50.0])    1.552869  ...   317.400000\n",
              "  (006_(50.0, inf], 006_(50.0, inf])     1.527054  ...   734.400000\n",
              "  \n",
              "  [49 rows x 9 columns]}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    }
  ]
}